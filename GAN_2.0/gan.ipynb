{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training our CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Define the directory containing .npy files\n",
    "directory_e = 'train/E'\n",
    "directory_s = 'train/S'\n",
    "directory_sb = 'train/SB'\n",
    "\n",
    "# Get a list of all .npy files in the directory\n",
    "files_e = [f for f in os.listdir(directory_e) if f.endswith('.jpg')]\n",
    "files_s = [f for f in os.listdir(directory_s) if f.endswith('.jpg')]\n",
    "files_sb = [f for f in os.listdir(directory_sb) if f.endswith('.jpg')]\n",
    "\n",
    "data_e = []\n",
    "data_s = []\n",
    "data_sb = []\n",
    "\n",
    "for file in files_e:\n",
    "    file_path = os.path.join(directory_e, file)\n",
    "    image = Image.open(file_path)\n",
    "    image = image.resize((28,28))\n",
    "    data_e.append(image)\n",
    "for file in files_s:\n",
    "    file_path = os.path.join(directory_s, file)\n",
    "    image = Image.open(file_path)\n",
    "    image = image.resize((28,28))\n",
    "    data_s.append(image)\n",
    "for file in files_sb:\n",
    "    file_path = os.path.join(directory_sb, file)\n",
    "    image = Image.open(file_path)\n",
    "    image = image.resize((28,28))\n",
    "    data_sb.append(image)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\surya\\AppData\\Local\\Temp\\ipykernel_18708\\3318312754.py:1: FutureWarning: The input object of type 'Image' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Image', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  data_e = np.array(data_e)\n",
      "C:\\Users\\surya\\AppData\\Local\\Temp\\ipykernel_18708\\3318312754.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  data_e = np.array(data_e)\n",
      "C:\\Users\\surya\\AppData\\Local\\Temp\\ipykernel_18708\\3318312754.py:2: FutureWarning: The input object of type 'Image' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Image', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  data_s = np.array(data_s)\n",
      "C:\\Users\\surya\\AppData\\Local\\Temp\\ipykernel_18708\\3318312754.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  data_s = np.array(data_s)\n",
      "C:\\Users\\surya\\AppData\\Local\\Temp\\ipykernel_18708\\3318312754.py:3: FutureWarning: The input object of type 'Image' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Image', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  data_sb = np.array(data_sb)\n",
      "C:\\Users\\surya\\AppData\\Local\\Temp\\ipykernel_18708\\3318312754.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  data_sb = np.array(data_sb)\n"
     ]
    }
   ],
   "source": [
    "data_e = np.array(data_e)\n",
    "data_s = np.array(data_s)\n",
    "data_sb = np.array(data_sb)\n",
    "for e in range(len(data_e)):\n",
    "    data_e[e] = np.array(data_e[e])\n",
    "    # print(e.shape)\n",
    "for s in range(len(data_s)):\n",
    "    data_s[s] = np.array(data_s[s])\n",
    "for sb in range(len(data_sb)):\n",
    "    data_sb[sb] = np.array(data_sb[sb])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 3)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_e[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_grayscale(image_array):\n",
    "    \"\"\"\n",
    "    Convert an RGB image to grayscale using the luminosity method.\n",
    "    The weights are based on the human perception of colors.\n",
    "    \"\"\"\n",
    "    r, g, b = image_array[:,:,0], image_array[:,:,1], image_array[:,:,2]\n",
    "    grayscale_image = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "    return grayscale_image\n",
    "\n",
    "\n",
    "for e in range(len(data_e)):\n",
    "    data_e[e] = rgb_to_grayscale(data_e[e])\n",
    "    # print(e.shape)\n",
    "for s in range(len(data_s)):\n",
    "    data_s[s] = rgb_to_grayscale(data_s[s])\n",
    "for sb in range(len(data_sb)):\n",
    "    data_sb[sb] = rgb_to_grayscale(data_sb[sb])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_e[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for e in range(len(data_e)):\n",
    "#     # print(data_e[e].shape)\n",
    "#     data_e[e] = data_e[e].reshape(256,256)\n",
    "# for s in range(len(data_s)):\n",
    "#     data_s[s] = data_s[s].reshape(256,256)\n",
    "# for sb in range(len(data_sb)):\n",
    "#     data_sb[sb] = data_sb[sb].reshape(256,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(len(data_e)):\n",
    "    data_e[e] = data_e[e].flatten()\n",
    "    # print(e.shape)\n",
    "for s in range(len(data_s)):\n",
    "    data_s[s] = data_s[s].flatten()\n",
    "for sb in range(len(data_sb)):\n",
    "    data_sb[sb] = data_sb[sb].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900,)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate((list(data_e),list(data_s),list(data_sb)),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2203, 784)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = 0\n",
    "s=1\n",
    "sb=2\n",
    "\n",
    "label=[]\n",
    "for i in range(data.shape[0]):\n",
    "    if i < 900:\n",
    "        label.append(e)\n",
    "    elif i >=900 and i < 1800:\n",
    "        label.append(s)\n",
    "    else:\n",
    "        label.append(sb)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label = np.expand_dims(np.array(label),axis=1)\n",
    "# label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2203, 785)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.concatenate((list(data), label),axis=1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_tuner\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow_probability import distributions as tfd\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout,Input,Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 1., 1., 2.])"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "# scaler_x = StandardScaler()\n",
    "# scaler_y = StandardScaler()\n",
    "\n",
    "# data_arr = np.array(df_merged_new)\n",
    "# data_arr = np.array(data_new)\n",
    "np.random.shuffle(data)\n",
    "X = data[:,0:-1]\n",
    "y = data[:,-1]\n",
    "\n",
    "# max(X[:,2])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.7716,   3.7716,   6.0595,   6.0595,   4.7715,   8.0809,\n",
       "         8.0701,   8.0593,   7.0702,   5.092 ,   5.793 ,   6.3476,\n",
       "         7.3475,   8.4722,   5.2445,   7.2443,   7.7712,   3.8856,\n",
       "         8.0593,   8.5862,   7.651 ,   8.8358,   5.2984,   8.711 ,\n",
       "        10.8248,   7.6572,   8.0593,   7.1734,   8.7711,   6.7713,\n",
       "         5.4725,   5.7606,   7.4615,   8.3582,   9.4182,   7.9946,\n",
       "         7.0594,   7.0702,   6.4832,   6.4832,   8.0593,   9.3473,\n",
       "        11.1299,   7.2443,   9.771 ,   8.7711,   9.0592,   8.5862,\n",
       "        10.2378,   8.3197,   7.5648,   7.9669,   8.2981,  10.5259,\n",
       "         9.0592,  11.173 ,   9.2441,   9.2441,   5.7714,   4.7715,\n",
       "        10.5321,  37.9593,  28.3732,   9.2333,   8.4722,  10.0483,\n",
       "         8.1733,   7.3691,   7.0702,  11.0698,  11.0698,   8.0701,\n",
       "         6.7713,  11.7708,  11.7708,  10.472 ,   7.4723,   8.1949,\n",
       "         8.7819,   9.771 ,  12.1128,  10.6399,   9.771 ,   7.7712,\n",
       "         5.2337,   6.2336,   3.4727,   6.6573,  16.7981,  58.74  ,\n",
       "        37.323 ,  10.6893,  11.2054,  12.7491,  11.7492,   9.4721,\n",
       "         7.0702,   7.1842,   8.0701,  10.7709,   9.771 ,  10.6569,\n",
       "         9.771 ,   8.1733,   9.7494,  11.3579,  12.3578,  11.646 ,\n",
       "        10.6569,  10.8849,  11.7708,  10.0699,   8.6463,  11.7492,\n",
       "         6.9454,  10.1408,  16.5701,  39.7374,  44.1823,  21.7376,\n",
       "        11.5644,   8.3582,   7.4723,   7.1842,  11.0097,  10.586 ,\n",
       "         7.0594,   7.4723,   9.771 ,   7.7712,  12.7707,  12.0589,\n",
       "         9.0376,   7.3583,   8.7711,  10.358 ,   8.7711,  12.3578,\n",
       "        13.5318,  12.8308,   8.483 ,   9.0592,   8.8312,   9.2549,\n",
       "        11.5859,  42.8358,  92.7725,  50.7965,  15.0433,   8.6679,\n",
       "         7.0702,  10.0699,  13.6674,  13.2437,   7.0594,   9.4721,\n",
       "        12.7707,   6.7112,  12.4225,  12.6136,  10.9943,  13.8307,\n",
       "        10.2979,  10.7709,  11.7708,  10.6461,  11.1083,   9.2225,\n",
       "        10.0699,   9.07  ,  11.8417,   6.0703,   7.4984,  19.6345,\n",
       "        48.3282,  28.3625,  15.9723,  12.1406,   9.543 ,  10.244 ,\n",
       "        13.0912,  11.6568,   7.7712,  13.7706,   9.07  ,  12.2977,\n",
       "        12.8246,  11.4288,  13.6027,  10.5429,  10.7108,   9.298 ,\n",
       "        12.7707,   8.0593,   8.3474,   9.4613,  10.7709,   9.07  ,\n",
       "         9.5969,   8.4121,   9.3904,   8.1841,   8.956 ,  13.5103,\n",
       "        15.4284,  12.4826,  10.9558,  12.8308,  14.635 ,  15.6133,\n",
       "         8.3582,   8.7711,   8.0701,  10.1839,  12.0697,  11.3148,\n",
       "        15.7165,   9.1301,  10.8418,  11.9557,  10.7709,  12.6567,\n",
       "         7.7712,   8.3582,   9.771 ,   6.1843,   8.3089,   9.1131,\n",
       "        10.2763,   9.5861,  10.7709,  12.9017,  13.0157,  14.7705,\n",
       "        14.5425,  19.7161,  19.5698,  19.3849,  12.8416,  15.9553,\n",
       "        11.9557,  12.0697,  10.3688,   9.771 ,  11.8139,  13.6997,\n",
       "         9.771 ,   8.3582,  10.13  ,  11.1299,   9.2441,  10.4289,\n",
       "         6.7713,   6.7713,   8.8959,  10.9989,  10.9881,   7.5863,\n",
       "        10.3472,  12.706 ,  13.7167,  17.6454,  13.4178,  18.727 ,\n",
       "        16.7164,  18.841 ,  19.5636,  15.564 ,  14.1404,  14.7274,\n",
       "        13.3146,  10.4289,  11.7169,  15.5316,  12.7707,  11.3579,\n",
       "         7.2443,  13.1297,   8.2442,  10.831 ,   9.07  ,   9.07  ,\n",
       "        13.0696,  10.7709,  10.7108,   8.3089,  12.461 ,  17.3465,\n",
       "        21.2922,  19.0043,  17.3681,  23.9653,  26.8402,  25.563 ,\n",
       "        24.1718,  22.172 ,  17.1617,  18.4281,  15.1187,  13.1297,\n",
       "        16.4992,  13.1898,  13.8199,  12.934 ,  10.5321,  13.0265,\n",
       "        12.8308,  15.4068,   9.184 ,  11.7708,  13.0696,  14.7705,\n",
       "        11.6075,  12.0312,  10.1839,  14.0587,  18.0475,  22.2043,\n",
       "        33.9366,  35.8332,  32.9968,  35.22  ,  40.2257,  37.927 ,\n",
       "        28.6721,  25.0854,  21.8407,  18.2648,  12.988 ,  12.9664,\n",
       "        11.5428,  12.0589,  13.2329,  12.7276,  13.1297,  16.5315,\n",
       "        12.0697,  17.0584,  11.059 ,   8.3582,  11.7708,   9.7926,\n",
       "         7.195 ,  11.7708,  17.0045,  30.4224,  64.4792,  48.2959,\n",
       "        43.4966,  59.2902,  58.5245,  52.807 ,  38.8515,  31.2374,\n",
       "        23.0363,  16.379 ,  12.1021,  12.6675,  14.4285,  10.3302,\n",
       "        11.2223,  12.2222,  17.6023,  27.2208,   6.4832,   9.0592,\n",
       "         8.3474,   7.2766,   9.9774,   9.7494,  10.7817,  10.6893,\n",
       "        18.4281,  21.2815,  30.33  ,  44.5027,  59.4859,  99.8273,\n",
       "       114.8752,  78.116 ,  48.8676,  35.9165,  20.3032,  17.325 ,\n",
       "        15.923 ,  10.3149,  11.532 ,  13.0911,  14.7489,  15.4822,\n",
       "        24.8789,  45.3131,   5.3801,  10.0699,  11.1299,  41.9913,\n",
       "        45.2406,  12.6675,  13.0696,   9.0916,  18.7979,  20.9333,\n",
       "        29.1775,  43.72  ,  65.356 , 122.7837, 143.7925,  88.3709,\n",
       "        53.6822,  37.5635,  24.1565,  24.3629,  23.9715,  15.7273,\n",
       "        13.4502,  17.912 ,  18.043 ,  19.2216,  17.1293,  47.4546,\n",
       "         5.4941,   8.4722,  15.4562,  90.7449,  83.4621,  14.4717,\n",
       "        14.6565,  12.5427,  15.5702,  21.4772,  27.8464,  32.205 ,\n",
       "        53.8563,  79.4103,  87.7408,  66.1326,  48.0957,  32.6241,\n",
       "        28.3687,  22.5156,  18.3742,  17.1185,  14.8414,  14.3253,\n",
       "        34.2866,  66.2191,  26.9113,  28.3176,   7.782 ,   5.7606,\n",
       "        13.7984,  33.3791,  29.3302,  13.5103,  11.4288,  16.3251,\n",
       "        13.6135,  14.0973,  20.1568,  24.5092,  39.2151,  47.6227,\n",
       "        49.0678,  43.0406,  38.2691,  31.5471,  22.8361,  20.4665,\n",
       "        18.9227,  12.8416,  15.0971,  14.8198,  21.8301,  38.2586,\n",
       "        22.0365,  20.5295,   8.3582,   6.7713,   7.6572,   7.1842,\n",
       "         9.9667,   8.5323,  11.1299,  11.4396,  10.9558,  14.8198,\n",
       "        15.4669,  22.705 ,  30.9323,  29.7152,  26.9219,  26.0252,\n",
       "        22.0364,  20.7915,  17.9551,  16.7873,  15.0263,  14.8414,\n",
       "        13.5426,  10.945 ,  14.0371,  15.4499,  12.689 ,  14.7751,\n",
       "         7.5432,   6.2444,   7.8313,   8.1302,   7.2443,   7.5324,\n",
       "         8.8312,   9.2549,   9.2441,  13.407 ,  13.4671,  14.1789,\n",
       "        15.4284,  23.46  ,  20.6174,  20.6837,  17.3851,  16.0693,\n",
       "        17.1185,  15.5316,  17.0153,  14.4285,  10.2656,  12.8416,\n",
       "        15.0971,  14.1296,  13.4933,  13.1235,   5.6574,   6.3692,\n",
       "         6.5433,   9.8419,  10.4397,  11.1191,  11.9449,  10.6677,\n",
       "         7.5432,   7.6464,  13.9447,  12.2438,  15.7381,  19.1723,\n",
       "        19.5035,  17.4991,  16.0755,  13.8846,  14.4285,  11.5428,\n",
       "        11.1299,  11.5428,  10.6677,  11.8417,  12.119 ,  12.5427,\n",
       "        13.1297,  16.3313,   6.7713,   7.5263,   7.4015,   8.369 ,\n",
       "         8.3474,   7.6464,  10.472 ,  11.7816,   7.1842,   8.0593,\n",
       "         8.7711,   7.7712,  10.8418,  15.564 ,  10.1516,  11.418 ,\n",
       "        13.3038,  13.8954,  13.9124,  17.5961,  13.8846,   9.885 ,\n",
       "        11.7708,  10.6569,  13.1297,  15.0586,  12.7815,  32.994 ,\n",
       "         3.7716,   8.483 ,   8.9991,   6.4015,  10.9989,   4.9995,\n",
       "         7.0486,   8.4722,   7.0702,   8.0593,   7.7712,  12.2438,\n",
       "        11.418 ,  12.2546,  10.2548,  10.8202,  10.244 ,  12.5535,\n",
       "        12.3363,  13.0804,   6.4724,  10.0699,   8.7711,  11.3579,\n",
       "        13.2437,   9.771 ,  12.4718,  23.2383,   6.1843,   8.3582,\n",
       "         9.8095,   8.3366,   8.7711,   8.7711,   7.4723,   6.4724,\n",
       "         8.1841,   9.0592,   8.1302,   5.2445,   7.8313,  10.13  ,\n",
       "        12.1406,   9.429 ,  11.1299,  11.1407,  10.4289,  13.2437,\n",
       "         9.3473,  11.0698,  11.3687,   8.4722,   8.8851,   8.0701,\n",
       "        10.9666,  17.4821,   4.7715,   8.6571,  24.2813,  17.2111,\n",
       "         5.7714,   8.3582,   6.7821,   5.7822,  10.472 ,   9.3689,\n",
       "         8.8312,   8.9452,   5.9455,   7.9453,   5.6574,   7.9561,\n",
       "         9.8203,   7.9453,   9.1732,   8.4614,  10.1731,   9.0808,\n",
       "        12.3794,  10.6569,   5.7714,  17.4821,  15.4438,  13.6566,\n",
       "         6.7713,   5.3693,  38.1984,  34.188 ,   5.1305,   5.0596,\n",
       "         8.7819,   6.0703,   9.771 ,  12.3686,   9.4721,   8.7711,\n",
       "        10.0699,  11.76  ,   7.7712,   7.7712,   9.1193,   8.5323,\n",
       "         7.6572,  18.6669,  15.6672,   9.2657,  10.2656,   8.5539,\n",
       "         6.1843,   8.483 ,   9.4937,  11.9449,   7.1734,   7.4723,\n",
       "         9.6247,   8.2119,   6.9454,   6.0811,   7.4723,   5.7606,\n",
       "         7.0486,   7.7712,   7.1842,   7.4831,   8.369 ,   4.7715,\n",
       "         5.7714,   7.7712,   5.2445,   7.1303,   7.4292,  16.3359,\n",
       "        12.9233,   8.4291,   7.9561,   8.9668,   5.9563,   8.7711,\n",
       "         9.4829,  12.9448,   7.0702,   7.3799,   7.5216,   7.5216,\n",
       "         7.4723,   5.1952,   6.7713,   8.0485,   5.0596,   7.0702,\n",
       "         6.7713,   3.7716,   4.4726,   5.7714,   7.7712,   8.3582,\n",
       "         8.1302,  10.13  ,   7.2443,   8.4183,   8.5215,  12.119 ,\n",
       "         6.5433,   7.554 ,  10.4289,   6.5325,   5.0596,  11.059 ,\n",
       "         4.0705,   7.081 ,   6.5325,   8.8312,   5.9563,   5.1844,\n",
       "         8.3582,   6.7605,   8.3582,   8.6679,   5.7714,   6.4724,\n",
       "         5.7714,   7.7712,   7.7712,   7.7712,   7.6572,   6.6573,\n",
       "         4.2446,   5.3585,   5.8854,   6.7713,   5.2661,   9.5646,\n",
       "         9.9559,   8.9452,   7.0594,  10.0591])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in range(len(X)):\n",
    "#     X[x] = (X[x]-127.5)/127.5\n",
    "\n",
    "X = X/255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9714733333333333"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.max(axis=1)\n",
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2203, 784)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = tf.keras.utils.to_categorical(y, num_classes=3)\n",
    "# y_test = tf.keras.utils.to_categorical(y_test, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = models.Sequential([\n",
    "    layers.InputLayer(shape=(28,28,1)),\n",
    "    layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
    "    layers.MaxPool2D(pool_size=(2,2),strides=1),\n",
    "    layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu'),\n",
    "    layers.MaxPool2D(pool_size=(2,2),strides=1),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(50,activation='relu'),\n",
    "    layers.Dense(3,activation='softmax'),\n",
    "    # layers.Dense(1,activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,464</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15488</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">774,450</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">153</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_12 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │        \u001b[38;5;34m18,464\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_13 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_7 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15488\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │       \u001b[38;5;34m774,450\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m153\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">793,707</span> (3.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m793,707\u001b[0m (3.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">793,707</span> (3.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m793,707\u001b[0m (3.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(-1,28,28)\n",
    "X = np.expand_dims(X,axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2203, 28, 28, 1)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAnCElEQVR4nO3dfWzd5X338c/vHNvHD7GPMSF23DhZQluyEZJpDLIImkFj5WG3ECmRBm3/CBUCwZxqkHWtMrVQtkneqMRQUQb/bKSVeGjRXYjKfS8VJMQRW8JECoq4u0VJlDVBiU0Jje344Txe9x8ZZiZx8PeL7ct23i/pSIn9+/q6znWu4885Pr/zPUkIIQgAgCmWij0BAMDliQACAERBAAEAoiCAAABREEAAgCgIIABAFAQQACAKAggAEEVF7Al8Urlc1qlTp1RfX68kSWJPBwBgFEJQf3+/WltblUqN/Txn2gXQqVOn1NbWFnsaAIDP6OTJk1qwYMGY3592AVRfXy9Juln/SxVJ5bjrkorxHztSU+W8+o7uRUmVfX5hOGeu0SUebYwlqa62jyOp3D9gLwplc4ln7ZIK521b6bidhobs46TT5pIkPXV/MS8P2ffetP6DheN+IUkhXzDXuO7rJfv9QmVfF7Ukbb+hysbfRUUV9Ib+78jv87FMWgBt375dP/jBD9Td3a0VK1boySef1I033vipdR/92a0iqbQFkOHYz1JzniOAHGOFxLHBEkcApars40gqJ3lPlbkiSezzSxLn1k55bqeSfZzEEUCO29arnHhup2mcQM61C46r5Nmvvj3kDCDHWpj3Q/horEsv4KTs6J/85CfaunWrHnnkEf3yl7/UihUrtG7dOr3//vuTMRwAYAaalAB6/PHHde+99+ob3/iGfu/3fk9PP/20amtr9c///M+TMRwAYAaa8ADK5/M6ePCg2tvbPx4klVJ7e7v2799/wfG5XE59fX2jLgCA2W/CA+iDDz5QqVRSc3PzqK83Nzeru7v7guM7OzuVzWZHLpwBBwCXh+hvRN22bZt6e3tHLidPnow9JQDAFJjws+Dmzp2rdDqtnp6eUV/v6elRS0vLBcdnMhllMpmJngYAYJqb8GdAVVVVuv7667V79+6Rr5XLZe3evVurVq2a6OEAADPUpLwPaOvWrdq8ebP+8A//UDfeeKOeeOIJDQwM6Bvf+MZkDAcAmIEmJYDuvPNO/eY3v9HDDz+s7u5u/f7v/7527dp1wYkJAIDLVxKCo6/MJOrr61M2m9WXq/9UFZZ3FHtaqOQ97+SXUp7XrFL2t1SHQtE+jqdNUP0c+ziS5GhT4lqHoWFzTeJ8XTEU7WvuapHjmF9SZX+HffnMh+YaydfKyHN/Sqrt61DqO2eu8bSAkqRUba2jyNFpYGDQPoyj5Y/k2+PWmmIoaK92qre3Vw0NDWMeF/0sOADA5YkAAgBEQQABAKIggAAAURBAAIAoCCAAQBQEEAAgCgIIABAFAQQAiIIAAgBEQQABAKIggAAAUUxKN+wJkU5LSXr8x5ftzQZTNdXmGknn52ZUdjRQTCodDSEdDUxTjkaukiTH+oVzA+YaV2NRb/PJOXX2Isd+8Aj9/eaaxNuw0tMI17MOif0xsOd+kThvI19zWvtYrvu6Y26Sr6mt9bZNQkrKffpxPAMCAERBAAEAoiCAAABREEAAgCgIIABAFAQQACAKAggAEAUBBACIggACAERBAAEAoiCAAABREEAAgCgIIABAFNO2G3bI5RWSMO7jU/X1kzibTyiVzCVJtb2jc6qu1lwTSvYu0GFoyFwjSYmjc7Sns3Wosdck5fHvnc8qeLoz5wv2mqYrzDWevSpJiafIcZ1C0XFf8nRzdnTLl5xdtBP76iWOGtXU2Gsk3ycHGO+3qZDQDRsAMH0RQACAKAggAEAUBBAAIAoCCAAQBQEEAIiCAAIAREEAAQCiIIAAAFEQQACAKAggAEAUBBAAIIpp24zUKuTG0fnuEzyNMSUpDDvGyjbYB6qstI+TFO3jVPjWoVzvaEZacMwvbX+cVK50NJGUlAzbG2qqwj5WucbRUNMhGRj2FQZHM9cqx351NDBVcDQW9Vwf+e7rnrGCoyZxNlj1CEXb/TaE8R3PMyAAQBQEEAAgCgIIABAFAQQAiIIAAgBEQQABAKIggAAAURBAAIAoCCAAQBQEEAAgCgIIABAFAQQAiGLaNiNNKtJKkvFPz9NYNKmtMddIklKJfawKx1JX2mtCbbW5Jhn0NaxMHA0US1fUmmtSQ/aGlUnR16ixOHeOq84qKZTsRY59l29uso8jqfKcvWlsute+j1x7r2S/bZMrsvZxJCVV9vmVPvytfRzH7wdPA+bzgzmedxgbwIYwvvssz4AAAFEQQACAKCY8gL7//e8rSZJRl6VLl070MACAGW5SXgO69tpr9dprr308iOf1DwDArDYpyVBRUaGWlpbJ+NEAgFliUl4DOnLkiFpbW7VkyRJ9/etf14kTJ8Y8NpfLqa+vb9QFADD7TXgArVy5Ujt27NCuXbv01FNP6fjx4/rSl76k/v7+ix7f2dmpbDY7cmlra5voKQEApqEkBMebOQzOnj2rRYsW6fHHH9c999xzwfdzuZxy/+N89r6+PrW1tenL1X+qiqRq3OMkNfb39HjfBxSGHe93qLa/P0eZ8V//jwTHe4e87wMKDXXmmlK9/f1aU/o+oEbne8OMpux9QFn7HpKm7n1Aqd/a/+IRBofMNd73AWmI9wGdH8x2fyqGgl4v/m/19vaqoaFhzOMm/eyAxsZGffGLX9TRo0cv+v1MJqOM402kAICZbdLfB3Tu3DkdO3ZM8+fPn+yhAAAzyIQH0Le+9S11dXXpv/7rv/Rv//Zv+spXvqJ0Oq2vfvWrEz0UAGAGm/A/wb333nv66le/qjNnzuiqq67SzTffrAMHDuiqq66a6KEAADPYhAfQCy+8MCE/J6mtVZIyvIBasL9oqqpKe42kpOR4AdkhpB1PUB0vVHtOJpCkUp3vBe4pGSexr4MkFescLwZ7mtMW0+aacpV9P+Qb7ONIvuuUcTQJVUWjvaY89ovaY8o5fj9I0oD9OqVqHA2BHSdRhQHfbVt2nFhhP3FhfMfTCw4AEAUBBACIggACAERBAAEAoiCAAABREEAAgCgIIABAFAQQACAKAggAEAUBBACIggACAERBAAEAopj0D6TzCoWCgqGhpOcTBTXs+0TB4Gi6mDiaY4YaexPOxNF0sZT1fSCg5fYZqamwP+YpZew1xTm+Ro1yfD5wudLR+DTYr1PimFs67/vA45C2X6dyxr7mpRr7/TaVszcDdu4GJdl6e1GvYyDP7y/Hpx9LUqpyjrkmGH9XJiFI4/ggY54BAQCiIIAAAFEQQACAKAggAEAUBBAAIAoCCAAQBQEEAIiCAAIAREEAAQCiIIAAAFEQQACAKAggAEAUBBAAIIpp2w07SaeUJIZ8TDk6Mzu7YScZe5dqVTs6TtubbquUrTHXJCVfx+TSHPv2KdY6OiY7umEXah0dqiUVqx1doCvt43g6iSdl++2UsjeOliRVDNrHChX2hUgP2Td5cNzXPV3OJSntuJ1S+WrfYEZJtsFVFwYG7UUlY00Y38bjGRAAIAoCCAAQBQEEAIiCAAIAREEAAQCiIIAAAFEQQACAKAggAEAUBBAAIAoCCAAQBQEEAIiCAAIARDFtm5GGQlHB0Iw0SdubXLpV2psuhhp7M9JQab9O5SpHs89a3zbwNAnNz5maxqKFel8z0sIce00p42jcmXY0Fi2aS5TK+dahcsBeV3TcTple+36oPGfvsOpdh3KN/b6eFO0NgT3jFOc4miJLyvzasV8Hh4wFQRr+9MN4BgQAiIIAAgBEQQABAKIggAAAURBAAIAoCCAAQBQEEAAgCgIIABAFAQQAiIIAAgBEQQABAKIggAAAUUzbZqRJOq0kGX9jzaTG3gBQwd6UT5JCtaMJYOJohpi215Qzjgamlc7GnXX2xy+5rKOxaIO9ZrjJd9sWs/ZGl6oqm0uSCntNyNtv22TI9xiz/Fv7WCFlv50Sx3KnCvbrlKr2NStOnbPfTuVq+6/VpGBfiPSwozutJBXtYyVVtmapSXl89z+eAQEAoiCAAABRmANo3759uu2229Ta2qokSfTyyy+P+n4IQQ8//LDmz5+vmpoatbe368iRIxM1XwDALGEOoIGBAa1YsULbt2+/6Pcfe+wx/fCHP9TTTz+tN998U3V1dVq3bp2Gh8fx6UQAgMuG+dWyDRs2aMOGDRf9XghBTzzxhL773e/q9ttvlyT9+Mc/VnNzs15++WXdddddn222AIBZY0JfAzp+/Li6u7vV3t4+8rVsNquVK1dq//79F63J5XLq6+sbdQEAzH4TGkDd3d2SpObm5lFfb25uHvneJ3V2diqbzY5c2traJnJKAIBpKvpZcNu2bVNvb+/I5eTJk7GnBACYAhMaQC0tLZKknp6eUV/v6ekZ+d4nZTIZNTQ0jLoAAGa/CQ2gxYsXq6WlRbt37x75Wl9fn958802tWrVqIocCAMxw5rPgzp07p6NHj478//jx43rnnXfU1NSkhQsX6sEHH9Tf/u3f6gtf+IIWL16s733ve2ptbdXGjRsnct4AgBnOHEBvvfWWbr311pH/b926VZK0efNm7dixQ9/+9rc1MDCg++67T2fPntXNN9+sXbt2qbq6euJmDQCY8ZIQnB05J0lfX5+y2azWXLFZFYmh6Wfa8dfEK7L2GklK2ccK1bZmfpJUmpMx1+Qb7eMUq31/ic012OuG5tkbVuYcjUWLVxXMNZJU1zhkrplTnTPXVKTsTS4HcvYmuAOD9j0kSYWz9rqqD+0NP2t67Puh5gP72lX12WskKfOh/bZNivaxUjl7Y9HUB73mGkkKRftYSV2t6fhiOafXjj+p3t7eS76uH/0sOADA5YkAAgBEQQABAKIggAAAURBAAIAoCCAAQBQEEAAgCgIIABAFAQQAiIIAAgBEQQABAKIggAAAURBAAIAozB/HMFXKg0MqJ+Pv2pqqcXzcg7MReKixdyVOBu1ddVVrHydVsF+nYGt0O6JYZ+9kXJjj6GzdUDLX1GbtXa0l6XNZe4fhBXVnzTUVKft1OpOrM9ecqLjCXCNJH5btj02LOXtNwbGHqnrtNaWMvUaSQspel3Z0tg6ODvuqsne+l6TEM1Yubzu+PL7jeQYEAIiCAAIAREEAAQCiIIAAAFEQQACAKAggAEAUBBAAIAoCCAAQBQEEAIiCAAIAREEAAQCiIIAAAFFM22akqWyDUil7M06LpFT2FeYK9ppK+1InjmappYz9MYW3UWPJcfOUHTVJjb1xZ121sXnif1s457fmmo1XHjTXtFWcNdf84ty15prhkq9h5WDOfkMNVNvHKjv2q6eBaTrv3OPVaXNN4tjk6UHH75TEd51UdDRLLdt+V4by+O6zPAMCAERBAAEAoiCAAABREEAAgCgIIABAFAQQACAKAggAEAUBBACIggACAERBAAEAoiCAAABREEAAgCimbTNSFYtSavz5mFRXO8awN7mUpGQoZ64pN86x11Q4Hh/Y+5cqeJsaesoc81NiL0qnfI1m6yrst62nsejyKvt+PVL1G3PNwcpF5hrJuX6O28mzH1JFe5GnRpJC2r7Jk7J9LM84Kvl+f6nC8Wv/3IDt+DC+5qo8AwIAREEAAQCiIIAAAFEQQACAKAggAEAUBBAAIAoCCAAQBQEEAIiCAAIAREEAAQCiIIAAAFEQQACAKKZtM9IwOKiQFCd3EG8TzqZG+1B5+3VJFR03j/MqeXhunnTeXlMs2B8n5Qq+rf1Bzt40ds/AUnPNr3K95ppDg23mmt8O15prJCmXt69f4ridUuPrWTm6xrHvPH1SJSlVsBcmBXuT0NSg447haHoqSSHvGGuS8AwIABAFAQQAiMIcQPv27dNtt92m1tZWJUmil19+edT37777biVJMuqyfv36iZovAGCWMAfQwMCAVqxYoe3bt495zPr163X69OmRy/PPP/+ZJgkAmH3MrzRu2LBBGzZsuOQxmUxGLS0t7kkBAGa/SXkNaO/evZo3b56uueYaPfDAAzpz5syYx+ZyOfX19Y26AABmvwkPoPXr1+vHP/6xdu/erb//+79XV1eXNmzYoNIYn1/e2dmpbDY7cmlrs59qCgCYeSb8fUB33XXXyL+vu+46LV++XFdffbX27t2rNWvWXHD8tm3btHXr1pH/9/X1EUIAcBmY9NOwlyxZorlz5+ro0aMX/X4mk1FDQ8OoCwBg9pv0AHrvvfd05swZzZ8/f7KHAgDMIOY/wZ07d27Us5njx4/rnXfeUVNTk5qamvToo49q06ZNamlp0bFjx/Ttb39bn//857Vu3boJnTgAYGYzB9Bbb72lW2+9deT/H71+s3nzZj311FM6dOiQfvSjH+ns2bNqbW3V2rVr9Td/8zfKZDITN2sAwIxnDqBbbrlFIYzdBO8Xv/jFZ5rQR5KaGiVJ1biPL5350DxG2vl6U5JzNPPL27uEJnWO0Hb0J0znfU0NK4btNcUhxzoM2M+VGRjyPeA51nuluaavUG2uqXJ01DwzXGeu+eCcvUaScv329as4Z/+Lftqxhzz7NVX07fFypX2/lqscjVxL9vmFdNpcI0mp/gH7WHlH19hxoBccACAKAggAEAUBBACIggACAERBAAEAoiCAAABREEAAgCgIIABAFAQQACAKAggAEAUBBACIggACAERBAAEAopjwj+SeKCGXU0jG3yE2VW3vSOwVBu0tfJPM+Dt7fyTVO2iuyVR4HlP4OkcXq+3deCvtjXhV6rV3JM5X1NgHktSTs98lfltda65Jpezdjwt5+9yKg767eLrXXlfZb7+dKobs65CUzCVKD5XtRfJ1qU4u8WkBYylX29c73+i732Z+Y7/fpo2fAJCMc7l5BgQAiIIAAgBEQQABAKIggAAAURBAAIAoCCAAQBQEEAAgCgIIABAFAQQAiIIAAgBEQQABAKIggAAAUUzbZqRWSZW92Wc5l/ON5Wg2mFTYGwAmRXvXxfSgrWmg5G1FKoUKT6V9HUJib3KZKtjHkaT8oP0xWd6x9wx9dj+ucTThrBqyr50kVQw4Govae+eqYsheU+loLOpZb0lKOZqRevZrcDQRztf7nj9UOhrNpgoF0/GhPL7jeQYEAIiCAAIAREEAAQCiIIAAAFEQQACAKAggAEAUBBAAIAoCCAAQBQEEAIiCAAIAREEAAQCiIIAAAFFM32akSXL+Mk7B0SBUJUd3R2ddcDQWTcr2potyrENquGgfR1LmjP3xS0g5GosW7TWVg74mnJX99rpStb3G01g0cWyHlK2H5IiKAfs+qsjZa6rOORqLetau6OtGmhQ8jU8d90FHE+Hs/xsw10iS8s5NMQl4BgQAiIIAAgBEQQABAKIggAAAURBAAIAoCCAAQBQEEAAgCgIIABAFAQQAiIIAAgBEQQABAKIggAAAUUzfZqSlkq3roKexaDptr5GUZDL2mqpK+0CeBqaDOXNNquxr1Bgy9vXLfGhvhJius49TyPseW1UO2BuLhil6GFdO2+eWzvtuW09j0XTO3rgz5alxNhb1SBXt80t/aG8SmuTszUi9TUXDsP13hIJxHcL4fnfxDAgAEAUBBACIwhRAnZ2duuGGG1RfX6958+Zp48aNOnz48KhjhoeH1dHRoSuvvFJz5szRpk2b1NPTM6GTBgDMfKYA6urqUkdHhw4cOKBXX31VhUJBa9eu1cDAx3/zfOihh/Tzn/9cL774orq6unTq1CndcccdEz5xAMDMZjoJYdeuXaP+v2PHDs2bN08HDx7U6tWr1dvbq3/6p3/Sc889py9/+cuSpGeeeUa/+7u/qwMHDuiP/uiPJm7mAIAZ7TO9BtTb2ytJampqkiQdPHhQhUJB7e3tI8csXbpUCxcu1P79+y/6M3K5nPr6+kZdAACznzuAyuWyHnzwQd10001atmyZJKm7u1tVVVVqbGwcdWxzc7O6u7sv+nM6OzuVzWZHLm1tbd4pAQBmEHcAdXR06N1339ULL7zwmSawbds29fb2jlxOnjz5mX4eAGBmcL0RdcuWLXrllVe0b98+LViwYOTrLS0tyufzOnv27KhnQT09PWppabnoz8pkMso43tgJAJjZTM+AQgjasmWLXnrpJe3Zs0eLFy8e9f3rr79elZWV2r1798jXDh8+rBMnTmjVqlUTM2MAwKxgegbU0dGh5557Tjt37lR9ff3I6zrZbFY1NTXKZrO65557tHXrVjU1NamhoUHf/OY3tWrVKs6AAwCMYgqgp556SpJ0yy23jPr6M888o7vvvluS9A//8A9KpVLatGmTcrmc1q1bp3/8x3+ckMkCAGaPJIQwdZ39xqGvr0/ZbFa3Zv5UFcn4G3imHK8jhWLRXCNJSuxNIRNP49OUY5yaGnNNKNsbLkpSUldrrik1zTHXlCvta1eqcfbZtS+5SyljP/8nOJqReqWHHM19HSoG7ffBVM5eExx7SJKSnKMhsKMxcjLsaCz6mw/tNZK9sahkbtxcLOe1+8Md6u3tVUNDw5jH0QsOABAFAQQAiIIAAgBEQQABAKIggAAAURBAAIAoCCAAQBQEEAAgCgIIABAFAQQAiIIAAgBEQQABAKIggAAAUThbBk++JJESS9dpT+foqvF32/6fQt7eudbVdLzkqCk4uup6G6I71iHdc9Zck8rYb6dUvb1Tt1e52n43Sg86BnI0ww6VvseYSdG+J9IDeXNNcHSW9zxsTg057heSQso+WOrcsH2c/gFzjVsyfZ53TJ+ZAAAuKwQQACAKAggAEAUBBACIggACAERBAAEAoiCAAABREEAAgCgIIABAFAQQACAKAggAEAUBBACIYto2I1UqZWqaF4Zz5iFcDUIlJVVV5prygL37ZFJpv3nK/f3mmlRdnblGkpJae8PPMDRkH8dcIaVS9oaQkqSKtKPG/jguyfmaY05rjsaiqSF7A1OlHY+bvfd1RzNSDTn2XrFor6lw/voOZXtN2ni/KI9vDJ4BAQCiIIAAAFEQQACAKAggAEAUBBAAIAoCCAAQBQEEAIiCAAIAREEAAQCiIIAAAFEQQACAKAggAEAU07YZacgXFAy9DUPZ0WywXLLXSEocTQBTVZXmGlezVEdDSJV861A+86G5xrN2rqaLeUeTS0mJp6FmwdHM1dH0NBl0NLn07AdJ5QZ7o9mk6GhyOc6mlaPGKdgbd4aM/f4nSXKMZW7cKSmZ49hDBV9D25BzXCdrs9Qwvvsfz4AAAFEQQACAKAggAEAUBBAAIAoCCAAQBQEEAIiCAAIAREEAAQCiIIAAAFEQQACAKAggAEAUBBAAIIpp24x0SqTsTQPP19lzO1ib+cnZ9LSm2lxTPjdgrpGkVLbBXBOGHA01B4fsNSlnE87hnGMox1iO5rQqOprGesaRlAw7Gl16Gqx6mn2WHA1MHU1P3TxNhD3D5HwNdz3Nh62NkUMY33rzDAgAEAUBBACIwhRAnZ2duuGGG1RfX6958+Zp48aNOnz48KhjbrnlFiVJMupy//33T+ikAQAznymAurq61NHRoQMHDujVV19VoVDQ2rVrNTAw+jWEe++9V6dPnx65PPbYYxM6aQDAzGd6lXvXrl2j/r9jxw7NmzdPBw8e1OrVq0e+Xltbq5aWlomZIQBgVvpMrwH19vZKkpqamkZ9/dlnn9XcuXO1bNkybdu2TYODg2P+jFwup76+vlEXAMDs5z4Nu1wu68EHH9RNN92kZcuWjXz9a1/7mhYtWqTW1lYdOnRI3/nOd3T48GH97Gc/u+jP6ezs1KOPPuqdBgBghkqC9QTv//bAAw/oX/7lX/TGG29owYIFYx63Z88erVmzRkePHtXVV199wfdzuZxyuY/fe9HX16e2tjbdWrFJFcn438MQylNz7r0kpepqzTUhbz9n3/M+oKTSXjPd3wfkWQfv+4CC531AVzTaB5rm7wMKjn3keh/QoON9YY73ASk9hSf8et7b5HgvWRgY+y9LlzQF7wMqhrz29D+r3t5eNTSM/XvC9Qxoy5YteuWVV7Rv375Lho8krVy5UpLGDKBMJqNMJuOZBgBgBjMFUAhB3/zmN/XSSy9p7969Wrx48afWvPPOO5Kk+fPnuyYIAJidTAHU0dGh5557Tjt37lR9fb26u7slSdlsVjU1NTp27Jiee+45/cmf/ImuvPJKHTp0SA899JBWr16t5cuXT8oVAADMTKYAeuqppySdf7Pp//TMM8/o7rvvVlVVlV577TU98cQTGhgYUFtbmzZt2qTvfve7EzZhAMDsYP4T3KW0tbWpq6vrM00IAHB5mL7dsNNpKRn/WTWGQz/mOBtEksrnzplrkgr72UieDtohZz+Ly6vc51gHx9lIrjMIq30ntiRVVeaa4Om07DjbznU2oOfMOTm7Rw86ajxnZA05uqNX2m9XybePwrD9zL6Qd3Qfd/Lcn8xjhPFdH5qRAgCiIIAAAFEQQACAKAggAEAUBBAAIAoCCAAQBQEEAIiCAAIAREEAAQCiIIAAAFEQQACAKAggAEAU07YZacjnFZLxfwxsyvGpqkmt/aO1JansaPjpahLq+Jhezzp4mp5KUuL4uOfyoP1jhF0NQgccDSudUo6P/07q6sw1YdBxnZwfyZ049l7Z8RHRro9Ar6k216jsa8oanB9Xb+Vab8fH20tyfVy9dX7jPZpnQACAKAggAEAUBBAAIAoCCAAQBQEEAIiCAAIAREEAAQCiIIAAAFEQQACAKAggAEAUBBAAIIpp1wsuhPP934qhYKpLBUd/o/G3mhulbJybJAVHzfg7Kn3Msw4h+PpkJY6xPGvnGUfBeeM6pELaXJOU7Xe9EPLmGpV96+DqTeaYn+d+kQqOx83lsr1Gmrp95LgPeu5L58dy/K40Hv/R7+/wKes37QKov79fkvSG/o9kue09ffmcvfymjGfvT+V18vUwtXP0cZ1SZ6eoBuc5f+9i6vX39yubzY75/SR8WkRNsXK5rFOnTqm+vv6CR2F9fX1qa2vTyZMn1dDQEGmG8bEO57EO57EO57EO502HdQghqL+/X62trUqlxn7GOu2eAaVSKS1YsOCSxzQ0NFzWG+wjrMN5rMN5rMN5rMN5sdfhUs98PsJJCACAKAggAEAUMyqAMpmMHnnkEWUcn/o5m7AO57EO57EO57EO582kdZh2JyEAAC4PM+oZEABg9iCAAABREEAAgCgIIABAFDMmgLZv367f+Z3fUXV1tVauXKl///d/jz2lKff9739fSZKMuixdujT2tCbdvn37dNttt6m1tVVJkujll18e9f0Qgh5++GHNnz9fNTU1am9v15EjR+JMdhJ92jrcfffdF+yP9evXx5nsJOns7NQNN9yg+vp6zZs3Txs3btThw4dHHTM8PKyOjg5deeWVmjNnjjZt2qSenp5IM54c41mHW2655YL9cP/990ea8cXNiAD6yU9+oq1bt+qRRx7RL3/5S61YsULr1q3T+++/H3tqU+7aa6/V6dOnRy5vvPFG7ClNuoGBAa1YsULbt2+/6Pcfe+wx/fCHP9TTTz+tN998U3V1dVq3bp2Gh6d7sz+bT1sHSVq/fv2o/fH8889P4QwnX1dXlzo6OnTgwAG9+uqrKhQKWrt2rQYGBkaOeeihh/Tzn/9cL774orq6unTq1CndcccdEWc98cazDpJ07733jtoPjz32WKQZjyHMADfeeGPo6OgY+X+pVAqtra2hs7Mz4qym3iOPPBJWrFgRexpRSQovvfTSyP/L5XJoaWkJP/jBD0a+dvbs2ZDJZMLzzz8fYYZT45PrEEIImzdvDrfffnuU+cTy/vvvB0mhq6srhHD+tq+srAwvvvjiyDH/8R//ESSF/fv3x5rmpPvkOoQQwh//8R+HP//zP483qXGY9s+A8vm8Dh48qPb29pGvpVIptbe3a//+/RFnFseRI0fU2tqqJUuW6Otf/7pOnDgRe0pRHT9+XN3d3aP2Rzab1cqVKy/L/bF3717NmzdP11xzjR544AGdOXMm9pQmVW9vrySpqalJknTw4EEVCoVR+2Hp0qVauHDhrN4Pn1yHjzz77LOaO3euli1bpm3btmlwcDDG9MY07ZqRftIHH3ygUqmk5ubmUV9vbm7Wf/7nf0aaVRwrV67Ujh07dM011+j06dN69NFH9aUvfUnvvvuu6uvrY08viu7ubkm66P746HuXi/Xr1+uOO+7Q4sWLdezYMf3VX/2VNmzYoP379yudtn9m0XRXLpf14IMP6qabbtKyZcsknd8PVVVVamxsHHXsbN4PF1sHSfra176mRYsWqbW1VYcOHdJ3vvMdHT58WD/72c8izna0aR9A+NiGDRtG/r18+XKtXLlSixYt0k9/+lPdc889EWeG6eCuu+4a+fd1112n5cuX6+qrr9bevXu1Zs2aiDObHB0dHXr33Xcvi9dBL2WsdbjvvvtG/n3ddddp/vz5WrNmjY4dO6arr756qqd5UdP+T3Bz585VOp2+4CyWnp4etbS0RJrV9NDY2KgvfvGLOnr0aOypRPPRHmB/XGjJkiWaO3furNwfW7Zs0SuvvKLXX3991Me3tLS0KJ/P6+zZs6OOn637Yax1uJiVK1dK0rTaD9M+gKqqqnT99ddr9+7dI18rl8vavXu3Vq1aFXFm8Z07d07Hjh3T/PnzY08lmsWLF6ulpWXU/ujr69Obb7552e+P9957T2fOnJlV+yOEoC1btuill17Snj17tHjx4lHfv/7661VZWTlqPxw+fFgnTpyYVfvh09bhYt555x1Jml77IfZZEOPxwgsvhEwmE3bs2BF+9atfhfvuuy80NjaG7u7u2FObUn/xF38R9u7dG44fPx7+9V//NbS3t4e5c+eG999/P/bUJlV/f394++23w9tvvx0khccffzy8/fbb4de//nUIIYS/+7u/C42NjWHnzp3h0KFD4fbbbw+LFy8OQ0NDkWc+sS61Dv39/eFb3/pW2L9/fzh+/Hh47bXXwh/8wR+EL3zhC2F4eDj21CfMAw88ELLZbNi7d284ffr0yGVwcHDkmPvvvz8sXLgw7NmzJ7z11lth1apVYdWqVRFnPfE+bR2OHj0a/vqv/zq89dZb4fjx42Hnzp1hyZIlYfXq1ZFnPtqMCKAQQnjyySfDwoULQ1VVVbjxxhvDgQMHYk9pyt15551h/vz5oaqqKnzuc58Ld955Zzh69GjsaU26119/PUi64LJ58+YQwvlTsb/3ve+F5ubmkMlkwpo1a8Lhw4fjTnoSXGodBgcHw9q1a8NVV10VKisrw6JFi8K999476x6kXez6SwrPPPPMyDFDQ0Phz/7sz8IVV1wRamtrw1e+8pVw+vTpeJOeBJ+2DidOnAirV68OTU1NIZPJhM9//vPhL//yL0Nvb2/ciX8CH8cAAIhi2r8GBACYnQggAEAUBBAAIAoCCAAQBQEEAIiCAAIAREEAAQCiIIAAAFEQQACAKAggAEAUBBAAIAoCCAAQxf8HFIZROAtO/3kAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[4,:,:])\n",
    "print(y[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[356]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.04616   ],\n",
       "        [0.01915882],\n",
       "        [0.00739529],\n",
       "        [0.03439647],\n",
       "        [0.01984157],\n",
       "        [0.02376275],\n",
       "        [0.05513216],\n",
       "        [0.02768392],\n",
       "        [0.00920784],\n",
       "        [0.0394051 ],\n",
       "        [0.04332627],\n",
       "        [0.01587804],\n",
       "        [0.02372039],\n",
       "        [0.02372039],\n",
       "        [0.01361843],\n",
       "        [0.01321373],\n",
       "        [0.01506863],\n",
       "        [0.01547333],\n",
       "        [0.04914471],\n",
       "        [0.0479302 ],\n",
       "        [0.01979922],\n",
       "        [0.02141843],\n",
       "        [0.00505098],\n",
       "        [0.00784235],\n",
       "        [0.03113373],\n",
       "        [0.04848   ],\n",
       "        [0.02405882],\n",
       "        [0.0316898 ]],\n",
       "\n",
       "       [[0.03831765],\n",
       "        [0.01871176],\n",
       "        [0.02538196],\n",
       "        [0.03714549],\n",
       "        [0.00969725],\n",
       "        [0.02768392],\n",
       "        [0.04336863],\n",
       "        [0.01592039],\n",
       "        [0.01587804],\n",
       "        [0.02097137],\n",
       "        [0.01749725],\n",
       "        [0.00920784],\n",
       "        [0.03156275],\n",
       "        [0.05116863],\n",
       "        [0.02376275],\n",
       "        [0.02497725],\n",
       "        [0.02913412],\n",
       "        [0.01385412],\n",
       "        [0.04752549],\n",
       "        [0.05185137],\n",
       "        [0.02602235],\n",
       "        [0.03593098],\n",
       "        [0.0078    ],\n",
       "        [0.00436824],\n",
       "        [0.01775098],\n",
       "        [0.02608275],\n",
       "        [0.01063373],\n",
       "        [0.03904275]],\n",
       "\n",
       "       [[0.05121098],\n",
       "        [0.02768392],\n",
       "        [0.02376275],\n",
       "        [0.01984157],\n",
       "        [0.01199922],\n",
       "        [0.03944745],\n",
       "        [0.03552627],\n",
       "        [0.01199922],\n",
       "        [0.01199922],\n",
       "        [0.00690588],\n",
       "        [0.00807804],\n",
       "        [0.01984157],\n",
       "        [0.05008118],\n",
       "        [0.04846196],\n",
       "        [0.02404078],\n",
       "        [0.03972549],\n",
       "        [0.05217176],\n",
       "        [0.02517059],\n",
       "        [0.03733882],\n",
       "        [0.05298118],\n",
       "        [0.02787725],\n",
       "        [0.02440314],\n",
       "        [0.01195686],\n",
       "        [0.00622314],\n",
       "        [0.00784235],\n",
       "        [0.01685686],\n",
       "        [0.03023961],\n",
       "        [0.03646275]],\n",
       "\n",
       "       [[0.01244627],\n",
       "        [0.0085251 ],\n",
       "        [0.01199922],\n",
       "        [0.01592039],\n",
       "        [0.03507922],\n",
       "        [0.0472898 ],\n",
       "        [0.0316051 ],\n",
       "        [0.01984157],\n",
       "        [0.02376275],\n",
       "        [0.02331569],\n",
       "        [0.02768392],\n",
       "        [0.03944745],\n",
       "        [0.05400235],\n",
       "        [0.02655412],\n",
       "        [0.02796196],\n",
       "        [0.03580431],\n",
       "        [0.04432941],\n",
       "        [0.04040824],\n",
       "        [0.02949647],\n",
       "        [0.04469176],\n",
       "        [0.03179843],\n",
       "        [0.00920784],\n",
       "        [0.00920784],\n",
       "        [0.01907412],\n",
       "        [0.02231255],\n",
       "        [0.03524824],\n",
       "        [0.0677898 ],\n",
       "        [0.0454349 ]],\n",
       "\n",
       "       [[0.01592039],\n",
       "        [0.00807804],\n",
       "        [0.01984157],\n",
       "        [0.03552627],\n",
       "        [0.05031686],\n",
       "        [0.02840902],\n",
       "        [0.00694824],\n",
       "        [0.03669843],\n",
       "        [0.06762078],\n",
       "        [0.05933137],\n",
       "        [0.04247451],\n",
       "        [0.02448784],\n",
       "        [0.04134471],\n",
       "        [0.04134471],\n",
       "        [0.05451608],\n",
       "        [0.02242157],\n",
       "        [0.02909176],\n",
       "        [0.04825059],\n",
       "        [0.03414275],\n",
       "        [0.03022157],\n",
       "        [0.02674745],\n",
       "        [0.00920784],\n",
       "        [0.00920784],\n",
       "        [0.0163251 ],\n",
       "        [0.01839137],\n",
       "        [0.02231255],\n",
       "        [0.04583961],\n",
       "        [0.04309059]],\n",
       "\n",
       "       [[0.04684275],\n",
       "        [0.02768392],\n",
       "        [0.02259059],\n",
       "        [0.04336863],\n",
       "        [0.03071098],\n",
       "        [0.02840902],\n",
       "        [0.02101373],\n",
       "        [0.05747647],\n",
       "        [0.0554102 ],\n",
       "        [0.07663529],\n",
       "        [0.10638549],\n",
       "        [0.08403059],\n",
       "        [0.04530824],\n",
       "        [0.04716314],\n",
       "        [0.06768745],\n",
       "        [0.05754314],\n",
       "        [0.08309412],\n",
       "        [0.08863451],\n",
       "        [0.05888431],\n",
       "        [0.04594863],\n",
       "        [0.04635333],\n",
       "        [0.05419569],\n",
       "        [0.04724745],\n",
       "        [0.02416745],\n",
       "        [0.01839137],\n",
       "        [0.02231255],\n",
       "        [0.01677216],\n",
       "        [0.01911647]],\n",
       "\n",
       "       [[0.03855333],\n",
       "        [0.05031686],\n",
       "        [0.0345898 ],\n",
       "        [0.03851098],\n",
       "        [0.02080235],\n",
       "        [0.04825059],\n",
       "        [0.06280549],\n",
       "        [0.08980667],\n",
       "        [0.06167569],\n",
       "        [0.10210196],\n",
       "        [0.12675882],\n",
       "        [0.09975765],\n",
       "        [0.06450941],\n",
       "        [0.06406235],\n",
       "        [0.08155961],\n",
       "        [0.0810702 ],\n",
       "        [0.10783569],\n",
       "        [0.11175686],\n",
       "        [0.08386157],\n",
       "        [0.08268941],\n",
       "        [0.07614588],\n",
       "        [0.08790941],\n",
       "        [0.11301333],\n",
       "        [0.08601216],\n",
       "        [0.05783882],\n",
       "        [0.04373098],\n",
       "        [0.02137608],\n",
       "        [0.02259059]],\n",
       "\n",
       "       [[0.05031686],\n",
       "        [0.04684275],\n",
       "        [0.03066863],\n",
       "        [0.02791961],\n",
       "        [0.03256588],\n",
       "        [0.06785647],\n",
       "        [0.09121451],\n",
       "        [0.11199255],\n",
       "        [0.10990196],\n",
       "        [0.1452349 ],\n",
       "        [0.14244353],\n",
       "        [0.12562902],\n",
       "        [0.12846275],\n",
       "        [0.12409451],\n",
       "        [0.13374941],\n",
       "        [0.12978588],\n",
       "        [0.14159176],\n",
       "        [0.13605137],\n",
       "        [0.11297137],\n",
       "        [0.11572039],\n",
       "        [0.10205961],\n",
       "        [0.10088745],\n",
       "        [0.11932118],\n",
       "        [0.0777651 ],\n",
       "        [0.03431176],\n",
       "        [0.02367804],\n",
       "        [0.02048196],\n",
       "        [0.05003882]],\n",
       "\n",
       "       [[0.0316051 ],\n",
       "        [0.03552627],\n",
       "        [0.03806392],\n",
       "        [0.03414275],\n",
       "        [0.06001412],\n",
       "        [0.09922588],\n",
       "        [0.14425608],\n",
       "        [0.16111294],\n",
       "        [0.16507647],\n",
       "        [0.17845922],\n",
       "        [0.16394667],\n",
       "        [0.18864588],\n",
       "        [0.22005765],\n",
       "        [0.20045176],\n",
       "        [0.20550275],\n",
       "        [0.19883255],\n",
       "        [0.19749137],\n",
       "        [0.18455569],\n",
       "        [0.16629098],\n",
       "        [0.16673804],\n",
       "        [0.14689647],\n",
       "        [0.15077529],\n",
       "        [0.13063765],\n",
       "        [0.06830353],\n",
       "        [0.03184078],\n",
       "        [0.03454745],\n",
       "        [0.02787725],\n",
       "        [0.07380157]],\n",
       "\n",
       "       [[0.01753961],\n",
       "        [0.03115804],\n",
       "        [0.04752549],\n",
       "        [0.02237922],\n",
       "        [0.04040824],\n",
       "        [0.08354118],\n",
       "        [0.17562549],\n",
       "        [0.20469294],\n",
       "        [0.20153922],\n",
       "        [0.19761804],\n",
       "        [0.20433059],\n",
       "        [0.25530588],\n",
       "        [0.29500706],\n",
       "        [0.28324353],\n",
       "        [0.28211373],\n",
       "        [0.27729843],\n",
       "        [0.27595725],\n",
       "        [0.26071961],\n",
       "        [0.25029725],\n",
       "        [0.24407412],\n",
       "        [0.20530941],\n",
       "        [0.18453137],\n",
       "        [0.16484078],\n",
       "        [0.11309804],\n",
       "        [0.08673725],\n",
       "        [0.07145725],\n",
       "        [0.03571961],\n",
       "        [0.06757843]],\n",
       "\n",
       "       [[0.02768392],\n",
       "        [0.02768392],\n",
       "        [0.07335451],\n",
       "        [0.06943333],\n",
       "        [0.07962   ],\n",
       "        [0.08471333],\n",
       "        [0.17494275],\n",
       "        [0.20635451],\n",
       "        [0.22668549],\n",
       "        [0.24241255],\n",
       "        [0.28396863],\n",
       "        [0.3236698 ],\n",
       "        [0.34994588],\n",
       "        [0.38523647],\n",
       "        [0.39452902],\n",
       "        [0.38372627],\n",
       "        [0.37588392],\n",
       "        [0.34843569],\n",
       "        [0.32927686],\n",
       "        [0.30300078],\n",
       "        [0.23448588],\n",
       "        [0.19725569],\n",
       "        [0.19071216],\n",
       "        [0.13965216],\n",
       "        [0.09368549],\n",
       "        [0.07723333],\n",
       "        [0.04954941],\n",
       "        [0.06293216]],\n",
       "\n",
       "       [[0.03205216],\n",
       "        [0.05121098],\n",
       "        [0.1224749 ],\n",
       "        [0.14208078],\n",
       "        [0.16358392],\n",
       "        [0.1675051 ],\n",
       "        [0.2040102 ],\n",
       "        [0.23150078],\n",
       "        [0.27099059],\n",
       "        [0.30082549],\n",
       "        [0.35071333],\n",
       "        [0.38123098],\n",
       "        [0.41707765],\n",
       "        [0.48167137],\n",
       "        [0.50202667],\n",
       "        [0.48960471],\n",
       "        [0.46260353],\n",
       "        [0.41806275],\n",
       "        [0.37627098],\n",
       "        [0.32893882],\n",
       "        [0.2695651 ],\n",
       "        [0.2542851 ],\n",
       "        [0.22926549],\n",
       "        [0.15354863],\n",
       "        [0.11150314],\n",
       "        [0.10519529],\n",
       "        [0.09202392],\n",
       "        [0.0632102 ]],\n",
       "\n",
       "       [[0.05513216],\n",
       "        [0.07126392],\n",
       "        [0.12660745],\n",
       "        [0.13837098],\n",
       "        [0.17163765],\n",
       "        [0.22216588],\n",
       "        [0.24298627],\n",
       "        [0.28688667],\n",
       "        [0.32710157],\n",
       "        [0.35514824],\n",
       "        [0.39860157],\n",
       "        [0.45292431],\n",
       "        [0.5273    ],\n",
       "        [0.59754314],\n",
       "        [0.62205529],\n",
       "        [0.60707765],\n",
       "        [0.55514157],\n",
       "        [0.48886196],\n",
       "        [0.43240627],\n",
       "        [0.37533451],\n",
       "        [0.32957922],\n",
       "        [0.30387686],\n",
       "        [0.25974078],\n",
       "        [0.19668157],\n",
       "        [0.17682196],\n",
       "        [0.13454078],\n",
       "        [0.07823647],\n",
       "        [0.02399843]],\n",
       "\n",
       "       [[0.03115804],\n",
       "        [0.06252745],\n",
       "        [0.12829333],\n",
       "        [0.15574157],\n",
       "        [0.19959961],\n",
       "        [0.24827294],\n",
       "        [0.27738275],\n",
       "        [0.31898118],\n",
       "        [0.3500549 ],\n",
       "        [0.38662667],\n",
       "        [0.44442353],\n",
       "        [0.52736667],\n",
       "        [0.63311176],\n",
       "        [0.72547412],\n",
       "        [0.75411882],\n",
       "        [0.72507569],\n",
       "        [0.64609608],\n",
       "        [0.55030196],\n",
       "        [0.47379333],\n",
       "        [0.40770706],\n",
       "        [0.35383137],\n",
       "        [0.32258863],\n",
       "        [0.28444   ],\n",
       "        [0.23706549],\n",
       "        [0.19966627],\n",
       "        [0.13571294],\n",
       "        [0.09161922],\n",
       "        [0.04130235]],\n",
       "\n",
       "       [[0.01939451],\n",
       "        [0.07088353],\n",
       "        [0.13390039],\n",
       "        [0.16252078],\n",
       "        [0.19691725],\n",
       "        [0.24514353],\n",
       "        [0.29341216],\n",
       "        [0.33501059],\n",
       "        [0.35868902],\n",
       "        [0.3961549 ],\n",
       "        [0.46179412],\n",
       "        [0.55577569],\n",
       "        [0.67999686],\n",
       "        [0.78642471],\n",
       "        [0.81180667],\n",
       "        [0.77008157],\n",
       "        [0.67149608],\n",
       "        [0.5618298 ],\n",
       "        [0.47775686],\n",
       "        [0.40909059],\n",
       "        [0.36422941],\n",
       "        [0.34127608],\n",
       "        [0.28791412],\n",
       "        [0.23459451],\n",
       "        [0.1879451 ],\n",
       "        [0.12516392],\n",
       "        [0.11243961],\n",
       "        [0.08403059]],\n",
       "\n",
       "       [[0.03463216],\n",
       "        [0.10135882],\n",
       "        [0.1473498 ],\n",
       "        [0.17435098],\n",
       "        [0.19216863],\n",
       "        [0.22818431],\n",
       "        [0.29767804],\n",
       "        [0.34247255],\n",
       "        [0.36474314],\n",
       "        [0.40220902],\n",
       "        [0.46000588],\n",
       "        [0.53785569],\n",
       "        [0.64291804],\n",
       "        [0.73528039],\n",
       "        [0.75117647],\n",
       "        [0.71100392],\n",
       "        [0.62239373],\n",
       "        [0.52724   ],\n",
       "        [0.45331137],\n",
       "        [0.39483176],\n",
       "        [0.35412745],\n",
       "        [0.33856941],\n",
       "        [0.29462667],\n",
       "        [0.23459451],\n",
       "        [0.17226039],\n",
       "        [0.09771569],\n",
       "        [0.06191137],\n",
       "        [0.06095059]],\n",
       "\n",
       "       [[0.03972549],\n",
       "        [0.08987333],\n",
       "        [0.12365373],\n",
       "        [0.17418196],\n",
       "        [0.19221098],\n",
       "        [0.20442157],\n",
       "        [0.2757702 ],\n",
       "        [0.32403882],\n",
       "        [0.35459882],\n",
       "        [0.3927898 ],\n",
       "        [0.44088941],\n",
       "        [0.49173804],\n",
       "        [0.55714157],\n",
       "        [0.61510745],\n",
       "        [0.62356588],\n",
       "        [0.59863098],\n",
       "        [0.53751137],\n",
       "        [0.46588471],\n",
       "        [0.41895725],\n",
       "        [0.38031922],\n",
       "        [0.33545804],\n",
       "        [0.31088549],\n",
       "        [0.28290549],\n",
       "        [0.20993765],\n",
       "        [0.16049686],\n",
       "        [0.09816275],\n",
       "        [0.0263851 ],\n",
       "        [0.01826471]],\n",
       "\n",
       "       [[0.01826471],\n",
       "        [0.03979216],\n",
       "        [0.06824353],\n",
       "        [0.14896902],\n",
       "        [0.17209137],\n",
       "        [0.16978941],\n",
       "        [0.23442549],\n",
       "        [0.27372196],\n",
       "        [0.31834745],\n",
       "        [0.36090667],\n",
       "        [0.4050851 ],\n",
       "        [0.43402588],\n",
       "        [0.46413882],\n",
       "        [0.49695843],\n",
       "        [0.51164   ],\n",
       "        [0.49661373],\n",
       "        [0.4543749 ],\n",
       "        [0.40700039],\n",
       "        [0.37761255],\n",
       "        [0.35146314],\n",
       "        [0.3080098 ],\n",
       "        [0.2829902 ],\n",
       "        [0.23585137],\n",
       "        [0.13430549],\n",
       "        [0.12804   ],\n",
       "        [0.13903608],\n",
       "        [0.09259804],\n",
       "        [0.04341098]],\n",
       "\n",
       "       [[0.02655412],\n",
       "        [0.03098902],\n",
       "        [0.06655765],\n",
       "        [0.12145412],\n",
       "        [0.13119373],\n",
       "        [0.13402745],\n",
       "        [0.20460863],\n",
       "        [0.24156078],\n",
       "        [0.27721412],\n",
       "        [0.32207529],\n",
       "        [0.36439882],\n",
       "        [0.37211451],\n",
       "        [0.39366   ],\n",
       "        [0.41722941],\n",
       "        [0.41209373],\n",
       "        [0.40648667],\n",
       "        [0.39399804],\n",
       "        [0.36699686],\n",
       "        [0.33279373],\n",
       "        [0.30413098],\n",
       "        [0.28331059],\n",
       "        [0.25784392],\n",
       "        [0.19708667],\n",
       "        [0.15597765],\n",
       "        [0.14434078],\n",
       "        [0.13023294],\n",
       "        [0.11382314],\n",
       "        [0.06369961]],\n",
       "\n",
       "       [[0.03277725],\n",
       "        [0.04364667],\n",
       "        [0.06050353],\n",
       "        [0.08520275],\n",
       "        [0.10412588],\n",
       "        [0.13206353],\n",
       "        [0.19019843],\n",
       "        [0.21886118],\n",
       "        [0.25564431],\n",
       "        [0.29982275],\n",
       "        [0.32690863],\n",
       "        [0.32124157],\n",
       "        [0.34229765],\n",
       "        [0.36194588],\n",
       "        [0.33490235],\n",
       "        [0.32953098],\n",
       "        [0.33805608],\n",
       "        [0.32556745],\n",
       "        [0.29993176],\n",
       "        [0.2751902 ],\n",
       "        [0.24333137],\n",
       "        [0.18374627],\n",
       "        [0.15395373],\n",
       "        [0.14651608],\n",
       "        [0.11297137],\n",
       "        [0.07186235],\n",
       "        [0.07299216],\n",
       "        [0.04756784]],\n",
       "\n",
       "       [[0.02768392],\n",
       "        [0.0472898 ],\n",
       "        [0.03669843],\n",
       "        [0.04454078],\n",
       "        [0.08189765],\n",
       "        [0.1266498 ],\n",
       "        [0.17116627],\n",
       "        [0.18851255],\n",
       "        [0.21236   ],\n",
       "        [0.24873843],\n",
       "        [0.26563765],\n",
       "        [0.24198392],\n",
       "        [0.25244863],\n",
       "        [0.27584902],\n",
       "        [0.26926314],\n",
       "        [0.26772824],\n",
       "        [0.26958314],\n",
       "        [0.26012157],\n",
       "        [0.23840706],\n",
       "        [0.21095882],\n",
       "        [0.16503451],\n",
       "        [0.10063412],\n",
       "        [0.10176392],\n",
       "        [0.10265804],\n",
       "        [0.06244314],\n",
       "        [0.02295333],\n",
       "        [0.02521294],\n",
       "        [0.02683216]],\n",
       "\n",
       "       [[0.01592039],\n",
       "        [0.02926078],\n",
       "        [0.02461451],\n",
       "        [0.02898275],\n",
       "        [0.05736745],\n",
       "        [0.08918392],\n",
       "        [0.13438314],\n",
       "        [0.1646651 ],\n",
       "        [0.16777686],\n",
       "        [0.19121961],\n",
       "        [0.19635529],\n",
       "        [0.17225451],\n",
       "        [0.17374706],\n",
       "        [0.19245882],\n",
       "        [0.20151529],\n",
       "        [0.20155725],\n",
       "        [0.19831882],\n",
       "        [0.18958235],\n",
       "        [0.17065922],\n",
       "        [0.13956784],\n",
       "        [0.1056851 ],\n",
       "        [0.08328784],\n",
       "        [0.08441765],\n",
       "        [0.08603686],\n",
       "        [0.0573498 ],\n",
       "        [0.01992627],\n",
       "        [0.00464627],\n",
       "        [0.01248863]],\n",
       "\n",
       "       [[0.00460392],\n",
       "        [0.01818   ],\n",
       "        [0.02832431],\n",
       "        [0.03778588],\n",
       "        [0.04377333],\n",
       "        [0.05206275],\n",
       "        [0.09289373],\n",
       "        [0.15062392],\n",
       "        [0.15143373],\n",
       "        [0.14989922],\n",
       "        [0.15531294],\n",
       "        [0.14067373],\n",
       "        [0.14698157],\n",
       "        [0.14504196],\n",
       "        [0.12200392],\n",
       "        [0.11347843],\n",
       "        [0.11808235],\n",
       "        [0.12761059],\n",
       "        [0.12049333],\n",
       "        [0.09170392],\n",
       "        [0.07467804],\n",
       "        [0.08392824],\n",
       "        [0.07815216],\n",
       "        [0.07192902],\n",
       "        [0.05965176],\n",
       "        [0.0390851 ],\n",
       "        [0.01875412],\n",
       "        [0.01592039]],\n",
       "\n",
       "       [[0.00460392],\n",
       "        [0.01818   ],\n",
       "        [0.02856   ],\n",
       "        [0.04658902],\n",
       "        [0.04982745],\n",
       "        [0.04243216],\n",
       "        [0.06018314],\n",
       "        [0.12413647],\n",
       "        [0.12373176],\n",
       "        [0.10489333],\n",
       "        [0.11192627],\n",
       "        [0.12081412],\n",
       "        [0.12918824],\n",
       "        [0.10926196],\n",
       "        [0.06444275],\n",
       "        [0.04920471],\n",
       "        [0.05425569],\n",
       "        [0.07207333],\n",
       "        [0.07077451],\n",
       "        [0.04473412],\n",
       "        [0.03744784],\n",
       "        [0.06008078],\n",
       "        [0.06517412],\n",
       "        [0.05272784],\n",
       "        [0.03378039],\n",
       "        [0.03746588],\n",
       "        [0.05125333],\n",
       "        [0.03439647]],\n",
       "\n",
       "       [[0.00577608],\n",
       "        [0.0170502 ],\n",
       "        [0.03733882],\n",
       "        [0.04865529],\n",
       "        [0.04635333],\n",
       "        [0.04635333],\n",
       "        [0.04449843],\n",
       "        [0.08767373],\n",
       "        [0.08839882],\n",
       "        [0.0621651 ],\n",
       "        [0.08091922],\n",
       "        [0.09506941],\n",
       "        [0.09259843],\n",
       "        [0.07226745],\n",
       "        [0.04002157],\n",
       "        [0.02090471],\n",
       "        [0.02365373],\n",
       "        [0.03452314],\n",
       "        [0.03435412],\n",
       "        [0.01474824],\n",
       "        [0.01038   ],\n",
       "        [0.02517059],\n",
       "        [0.0505949 ],\n",
       "        [0.03883137],\n",
       "        [0.0092502 ],\n",
       "        [0.02173882],\n",
       "        [0.05125333],\n",
       "        [0.0394898 ]],\n",
       "\n",
       "       [[0.01361843],\n",
       "        [0.02259059],\n",
       "        [0.05165804],\n",
       "        [0.03944745],\n",
       "        [0.02052431],\n",
       "        [0.0401302 ],\n",
       "        [0.04219647],\n",
       "        [0.04846196],\n",
       "        [0.05698706],\n",
       "        [0.05585725],\n",
       "        [0.07546314],\n",
       "        [0.05982078],\n",
       "        [0.02845137],\n",
       "        [0.03746588],\n",
       "        [0.03610039],\n",
       "        [0.01621647],\n",
       "        [0.01645216],\n",
       "        [0.02037333],\n",
       "        [0.0171349 ],\n",
       "        [0.01204157],\n",
       "        [0.00509333],\n",
       "        [0.01086941],\n",
       "        [0.04179176],\n",
       "        [0.03277725],\n",
       "        [0.00347412],\n",
       "        [0.01086941],\n",
       "        [0.00694824],\n",
       "        [0.0171349 ]],\n",
       "\n",
       "       [[0.00807804],\n",
       "        [0.01984157],\n",
       "        [0.03552627],\n",
       "        [0.01592039],\n",
       "        [0.00577608],\n",
       "        [0.02768392],\n",
       "        [0.03552627],\n",
       "        [0.03944745],\n",
       "        [0.0472898 ],\n",
       "        [0.05121098],\n",
       "        [0.05905333],\n",
       "        [0.0316051 ],\n",
       "        [0.00347412],\n",
       "        [0.01915882],\n",
       "        [0.04345333],\n",
       "        [0.03844471],\n",
       "        [0.03840235],\n",
       "        [0.0372302 ],\n",
       "        [0.01992627],\n",
       "        [0.00699059],\n",
       "        [0.00856745],\n",
       "        [0.01248863],\n",
       "        [0.03556863],\n",
       "        [0.02772627],\n",
       "        [0.00347412],\n",
       "        [0.01479059],\n",
       "        [0.01086941],\n",
       "        [0.00856745]],\n",
       "\n",
       "       [[0.00460392],\n",
       "        [0.0085251 ],\n",
       "        [0.01984157],\n",
       "        [0.01592039],\n",
       "        [0.02376275],\n",
       "        [0.03552627],\n",
       "        [0.01592039],\n",
       "        [0.0316051 ],\n",
       "        [0.06297451],\n",
       "        [0.0316051 ],\n",
       "        [0.03944745],\n",
       "        [0.05513216],\n",
       "        [0.03669843],\n",
       "        [0.01479059],\n",
       "        [0.02384745],\n",
       "        [0.03060235],\n",
       "        [0.04349569],\n",
       "        [0.04624471],\n",
       "        [0.02776863],\n",
       "        [0.01875412],\n",
       "        [0.02772627],\n",
       "        [0.03164745],\n",
       "        [0.04341098],\n",
       "        [0.03439647],\n",
       "        [0.01479059],\n",
       "        [0.03047529],\n",
       "        [0.03047529],\n",
       "        [0.00969725]]])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.4023 - loss: 1.0490 - val_accuracy: 0.6018 - val_loss: 1.0036\n",
      "Epoch 2/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5386 - loss: 1.0099 - val_accuracy: 0.5656 - val_loss: 0.9513\n",
      "Epoch 3/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5460 - loss: 0.9745 - val_accuracy: 0.6199 - val_loss: 0.9418\n",
      "Epoch 4/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5692 - loss: 0.9407 - val_accuracy: 0.6561 - val_loss: 0.8980\n",
      "Epoch 5/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5836 - loss: 0.9255 - val_accuracy: 0.5023 - val_loss: 0.9371\n",
      "Epoch 6/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6063 - loss: 0.9061 - val_accuracy: 0.6787 - val_loss: 0.8588\n",
      "Epoch 7/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6021 - loss: 0.8899 - val_accuracy: 0.6606 - val_loss: 0.8513\n",
      "Epoch 8/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5700 - loss: 0.9198 - val_accuracy: 0.6561 - val_loss: 0.8531\n",
      "Epoch 9/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6228 - loss: 0.8657 - val_accuracy: 0.6063 - val_loss: 0.8584\n",
      "Epoch 10/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6114 - loss: 0.8552 - val_accuracy: 0.6787 - val_loss: 0.8176\n",
      "Epoch 11/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6238 - loss: 0.8423 - val_accuracy: 0.6878 - val_loss: 0.8182\n",
      "Epoch 12/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6350 - loss: 0.8451 - val_accuracy: 0.6878 - val_loss: 0.8032\n",
      "Epoch 13/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6147 - loss: 0.8380 - val_accuracy: 0.6833 - val_loss: 0.8204\n",
      "Epoch 14/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6330 - loss: 0.8206 - val_accuracy: 0.6923 - val_loss: 0.7989\n",
      "Epoch 15/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6190 - loss: 0.8375 - val_accuracy: 0.6697 - val_loss: 0.8158\n",
      "Epoch 16/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6262 - loss: 0.8241 - val_accuracy: 0.6878 - val_loss: 0.7904\n",
      "Epoch 17/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6160 - loss: 0.8372 - val_accuracy: 0.6742 - val_loss: 0.7994\n",
      "Epoch 18/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6496 - loss: 0.7923 - val_accuracy: 0.6833 - val_loss: 0.8099\n",
      "Epoch 19/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6061 - loss: 0.8255 - val_accuracy: 0.6787 - val_loss: 0.7815\n",
      "Epoch 20/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6677 - loss: 0.7732 - val_accuracy: 0.6787 - val_loss: 0.7855\n",
      "Epoch 21/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6298 - loss: 0.8024 - val_accuracy: 0.6787 - val_loss: 0.7808\n",
      "Epoch 22/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6437 - loss: 0.7877 - val_accuracy: 0.6878 - val_loss: 0.7785\n",
      "Epoch 23/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6464 - loss: 0.7726 - val_accuracy: 0.6923 - val_loss: 0.7815\n",
      "Epoch 24/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6589 - loss: 0.7623 - val_accuracy: 0.6244 - val_loss: 0.8330\n",
      "Epoch 25/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6333 - loss: 0.7857 - val_accuracy: 0.6787 - val_loss: 0.7715\n",
      "Epoch 26/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6564 - loss: 0.7747 - val_accuracy: 0.6290 - val_loss: 0.8174\n",
      "Epoch 27/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6382 - loss: 0.7914 - val_accuracy: 0.6335 - val_loss: 0.7974\n",
      "Epoch 28/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6782 - loss: 0.7458 - val_accuracy: 0.6742 - val_loss: 0.7747\n",
      "Epoch 29/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6498 - loss: 0.7533 - val_accuracy: 0.6561 - val_loss: 0.7727\n",
      "Epoch 30/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6665 - loss: 0.7758 - val_accuracy: 0.6652 - val_loss: 0.7645\n",
      "Epoch 31/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6848 - loss: 0.7162 - val_accuracy: 0.6335 - val_loss: 0.7913\n",
      "Epoch 32/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6457 - loss: 0.7659 - val_accuracy: 0.6742 - val_loss: 0.7680\n",
      "Epoch 33/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6433 - loss: 0.7572 - val_accuracy: 0.6606 - val_loss: 0.7719\n",
      "Epoch 34/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6687 - loss: 0.7196 - val_accuracy: 0.6561 - val_loss: 0.7929\n",
      "Epoch 35/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6745 - loss: 0.7279 - val_accuracy: 0.6606 - val_loss: 0.7649\n",
      "Epoch 36/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6827 - loss: 0.7179 - val_accuracy: 0.6335 - val_loss: 0.8065\n",
      "Epoch 37/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6526 - loss: 0.7565 - val_accuracy: 0.6787 - val_loss: 0.7669\n",
      "Epoch 38/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6632 - loss: 0.7245 - val_accuracy: 0.6561 - val_loss: 0.7616\n",
      "Epoch 39/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6786 - loss: 0.7233 - val_accuracy: 0.6516 - val_loss: 0.7761\n",
      "Epoch 40/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6662 - loss: 0.7186 - val_accuracy: 0.6561 - val_loss: 0.7594\n",
      "Epoch 41/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7092 - loss: 0.6971 - val_accuracy: 0.6606 - val_loss: 0.7673\n",
      "Epoch 42/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6577 - loss: 0.7515 - val_accuracy: 0.6561 - val_loss: 0.7642\n",
      "Epoch 43/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6983 - loss: 0.7074 - val_accuracy: 0.6199 - val_loss: 0.7868\n",
      "Epoch 44/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7080 - loss: 0.7063 - val_accuracy: 0.6561 - val_loss: 0.7696\n",
      "Epoch 45/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6745 - loss: 0.7241 - val_accuracy: 0.6561 - val_loss: 0.7623\n",
      "Epoch 46/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6973 - loss: 0.6930 - val_accuracy: 0.6561 - val_loss: 0.7609\n",
      "Epoch 47/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6820 - loss: 0.6998 - val_accuracy: 0.6244 - val_loss: 0.8037\n",
      "Epoch 48/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6906 - loss: 0.7233 - val_accuracy: 0.6606 - val_loss: 0.7672\n",
      "Epoch 49/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7042 - loss: 0.6781 - val_accuracy: 0.6652 - val_loss: 0.7629\n",
      "Epoch 50/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6882 - loss: 0.6973 - val_accuracy: 0.6606 - val_loss: 0.7740\n",
      "Epoch 51/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6796 - loss: 0.6984 - val_accuracy: 0.6561 - val_loss: 0.7645\n",
      "Epoch 52/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7196 - loss: 0.6672 - val_accuracy: 0.6199 - val_loss: 0.7937\n",
      "Epoch 53/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7154 - loss: 0.6752 - val_accuracy: 0.6742 - val_loss: 0.7885\n",
      "Epoch 54/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7249 - loss: 0.6535 - val_accuracy: 0.6290 - val_loss: 0.7840\n",
      "Epoch 55/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7074 - loss: 0.6748 - val_accuracy: 0.6697 - val_loss: 0.7623\n",
      "Epoch 56/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7266 - loss: 0.6504 - val_accuracy: 0.6290 - val_loss: 0.7787\n",
      "Epoch 57/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7236 - loss: 0.6627 - val_accuracy: 0.6787 - val_loss: 0.7802\n",
      "Epoch 58/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7291 - loss: 0.6395 - val_accuracy: 0.6561 - val_loss: 0.7664\n",
      "Epoch 59/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7254 - loss: 0.6364 - val_accuracy: 0.6516 - val_loss: 0.7721\n",
      "Epoch 60/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7096 - loss: 0.6547 - val_accuracy: 0.6606 - val_loss: 0.7744\n",
      "Epoch 61/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7461 - loss: 0.6334 - val_accuracy: 0.6380 - val_loss: 0.7821\n",
      "Epoch 62/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7331 - loss: 0.6444 - val_accuracy: 0.6335 - val_loss: 0.7795\n",
      "Epoch 63/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7274 - loss: 0.6306 - val_accuracy: 0.6063 - val_loss: 0.7929\n",
      "Epoch 64/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7315 - loss: 0.6576 - val_accuracy: 0.6833 - val_loss: 0.7825\n",
      "Epoch 65/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7618 - loss: 0.6237 - val_accuracy: 0.6742 - val_loss: 0.7795\n",
      "Epoch 66/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7272 - loss: 0.6198 - val_accuracy: 0.6335 - val_loss: 0.7890\n",
      "Epoch 67/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7380 - loss: 0.6325 - val_accuracy: 0.6380 - val_loss: 0.7891\n",
      "Epoch 68/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7447 - loss: 0.6274 - val_accuracy: 0.5882 - val_loss: 0.8999\n",
      "Epoch 69/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7134 - loss: 0.6733 - val_accuracy: 0.6109 - val_loss: 0.8274\n",
      "Epoch 70/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7156 - loss: 0.6206 - val_accuracy: 0.6335 - val_loss: 0.7848\n",
      "Epoch 71/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7553 - loss: 0.6062 - val_accuracy: 0.6787 - val_loss: 0.7718\n",
      "Epoch 72/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7500 - loss: 0.6113 - val_accuracy: 0.6561 - val_loss: 0.7802\n",
      "Epoch 73/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7557 - loss: 0.5952 - val_accuracy: 0.6380 - val_loss: 0.8082\n",
      "Epoch 74/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7612 - loss: 0.5911 - val_accuracy: 0.6787 - val_loss: 0.7880\n",
      "Epoch 75/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7492 - loss: 0.5880 - val_accuracy: 0.6154 - val_loss: 0.8194\n",
      "Epoch 76/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7598 - loss: 0.5729 - val_accuracy: 0.6380 - val_loss: 0.8017\n",
      "Epoch 77/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7618 - loss: 0.5783 - val_accuracy: 0.6833 - val_loss: 0.7882\n",
      "Epoch 78/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7458 - loss: 0.5981 - val_accuracy: 0.6425 - val_loss: 0.8031\n",
      "Epoch 79/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7686 - loss: 0.5646 - val_accuracy: 0.6290 - val_loss: 0.8794\n",
      "Epoch 80/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7387 - loss: 0.6375 - val_accuracy: 0.6290 - val_loss: 0.8262\n",
      "Epoch 81/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7562 - loss: 0.5795 - val_accuracy: 0.6290 - val_loss: 0.8281\n",
      "Epoch 82/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7424 - loss: 0.6093 - val_accuracy: 0.6199 - val_loss: 0.8310\n",
      "Epoch 83/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7563 - loss: 0.5917 - val_accuracy: 0.6425 - val_loss: 0.8130\n",
      "Epoch 84/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7585 - loss: 0.5615 - val_accuracy: 0.6561 - val_loss: 0.7927\n",
      "Epoch 85/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7720 - loss: 0.5622 - val_accuracy: 0.6244 - val_loss: 0.8196\n",
      "Epoch 86/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7838 - loss: 0.5476 - val_accuracy: 0.6561 - val_loss: 0.8114\n",
      "Epoch 87/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7754 - loss: 0.5339 - val_accuracy: 0.6471 - val_loss: 0.8005\n",
      "Epoch 88/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8001 - loss: 0.5306 - val_accuracy: 0.6290 - val_loss: 0.8179\n",
      "Epoch 89/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7768 - loss: 0.5440 - val_accuracy: 0.6606 - val_loss: 0.8000\n",
      "Epoch 90/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7748 - loss: 0.5466 - val_accuracy: 0.6606 - val_loss: 0.7972\n",
      "Epoch 91/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7597 - loss: 0.5679 - val_accuracy: 0.6425 - val_loss: 0.8067\n",
      "Epoch 92/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7751 - loss: 0.5464 - val_accuracy: 0.6154 - val_loss: 0.8504\n",
      "Epoch 93/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7847 - loss: 0.5309 - val_accuracy: 0.6516 - val_loss: 0.8133\n",
      "Epoch 94/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7932 - loss: 0.5091 - val_accuracy: 0.6425 - val_loss: 0.8107\n",
      "Epoch 95/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7671 - loss: 0.5678 - val_accuracy: 0.6516 - val_loss: 0.7938\n",
      "Epoch 96/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7746 - loss: 0.5384 - val_accuracy: 0.6516 - val_loss: 0.7934\n",
      "Epoch 97/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8051 - loss: 0.5147 - val_accuracy: 0.6561 - val_loss: 0.7936\n",
      "Epoch 98/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8079 - loss: 0.4939 - val_accuracy: 0.6606 - val_loss: 0.8037\n",
      "Epoch 99/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8012 - loss: 0.5233 - val_accuracy: 0.6471 - val_loss: 0.8206\n",
      "Epoch 100/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7805 - loss: 0.5480 - val_accuracy: 0.6425 - val_loss: 0.8150\n",
      "Epoch 101/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7835 - loss: 0.5169 - val_accuracy: 0.6380 - val_loss: 0.8235\n",
      "Epoch 102/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7865 - loss: 0.5221 - val_accuracy: 0.6561 - val_loss: 0.8209\n",
      "Epoch 103/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8117 - loss: 0.4972 - val_accuracy: 0.6244 - val_loss: 0.8761\n",
      "Epoch 104/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7903 - loss: 0.5144 - val_accuracy: 0.6425 - val_loss: 0.8309\n",
      "Epoch 105/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8188 - loss: 0.4899 - val_accuracy: 0.6335 - val_loss: 0.8494\n",
      "Epoch 106/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8176 - loss: 0.4801 - val_accuracy: 0.6516 - val_loss: 0.8255\n",
      "Epoch 107/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8247 - loss: 0.4607 - val_accuracy: 0.6471 - val_loss: 0.8277\n",
      "Epoch 108/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8010 - loss: 0.5051 - val_accuracy: 0.6425 - val_loss: 0.8514\n",
      "Epoch 109/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8211 - loss: 0.4872 - val_accuracy: 0.6516 - val_loss: 0.8360\n",
      "Epoch 110/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7999 - loss: 0.4853 - val_accuracy: 0.6516 - val_loss: 0.8425\n",
      "Epoch 111/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8264 - loss: 0.4777 - val_accuracy: 0.6199 - val_loss: 0.8758\n",
      "Epoch 112/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8280 - loss: 0.4662 - val_accuracy: 0.6199 - val_loss: 0.8724\n",
      "Epoch 113/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7997 - loss: 0.5202 - val_accuracy: 0.6516 - val_loss: 0.8594\n",
      "Epoch 114/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8101 - loss: 0.4636 - val_accuracy: 0.6425 - val_loss: 0.8718\n",
      "Epoch 115/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8278 - loss: 0.4449 - val_accuracy: 0.6516 - val_loss: 0.8584\n",
      "Epoch 116/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8064 - loss: 0.4807 - val_accuracy: 0.6425 - val_loss: 0.8702\n",
      "Epoch 117/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8399 - loss: 0.4459 - val_accuracy: 0.6380 - val_loss: 0.8716\n",
      "Epoch 118/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8159 - loss: 0.4651 - val_accuracy: 0.6199 - val_loss: 0.8751\n",
      "Epoch 119/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8075 - loss: 0.4717 - val_accuracy: 0.6380 - val_loss: 0.8742\n",
      "Epoch 120/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8161 - loss: 0.4729 - val_accuracy: 0.6380 - val_loss: 0.9474\n",
      "Epoch 121/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8116 - loss: 0.4825 - val_accuracy: 0.6380 - val_loss: 0.9223\n",
      "Epoch 122/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8240 - loss: 0.4537 - val_accuracy: 0.6471 - val_loss: 0.8900\n",
      "Epoch 123/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8387 - loss: 0.4194 - val_accuracy: 0.6561 - val_loss: 0.8867\n",
      "Epoch 124/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8285 - loss: 0.4370 - val_accuracy: 0.6380 - val_loss: 0.8936\n",
      "Epoch 125/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8472 - loss: 0.4366 - val_accuracy: 0.6335 - val_loss: 0.8945\n",
      "Epoch 126/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8588 - loss: 0.4266 - val_accuracy: 0.6335 - val_loss: 0.8973\n",
      "Epoch 127/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8357 - loss: 0.4357 - val_accuracy: 0.6561 - val_loss: 0.9036\n",
      "Epoch 128/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8447 - loss: 0.4056 - val_accuracy: 0.6471 - val_loss: 0.8836\n",
      "Epoch 129/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8458 - loss: 0.4288 - val_accuracy: 0.6471 - val_loss: 0.8862\n",
      "Epoch 130/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8447 - loss: 0.4038 - val_accuracy: 0.6425 - val_loss: 0.8909\n",
      "Epoch 131/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8493 - loss: 0.4138 - val_accuracy: 0.6606 - val_loss: 0.9217\n",
      "Epoch 132/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8653 - loss: 0.4051 - val_accuracy: 0.6606 - val_loss: 0.9087\n",
      "Epoch 133/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8639 - loss: 0.3804 - val_accuracy: 0.6561 - val_loss: 0.9032\n",
      "Epoch 134/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8607 - loss: 0.3972 - val_accuracy: 0.6652 - val_loss: 0.9073\n",
      "Epoch 135/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8677 - loss: 0.3816 - val_accuracy: 0.6606 - val_loss: 0.9140\n",
      "Epoch 136/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8514 - loss: 0.4077 - val_accuracy: 0.6516 - val_loss: 0.9281\n",
      "Epoch 137/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8258 - loss: 0.4663 - val_accuracy: 0.6244 - val_loss: 0.9545\n",
      "Epoch 138/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8474 - loss: 0.4121 - val_accuracy: 0.6561 - val_loss: 0.9092\n",
      "Epoch 139/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8697 - loss: 0.3725 - val_accuracy: 0.6652 - val_loss: 0.9234\n",
      "Epoch 140/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8679 - loss: 0.3750 - val_accuracy: 0.6516 - val_loss: 0.9377\n",
      "Epoch 141/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8534 - loss: 0.3878 - val_accuracy: 0.6561 - val_loss: 0.9195\n",
      "Epoch 142/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8731 - loss: 0.3659 - val_accuracy: 0.6606 - val_loss: 0.9256\n",
      "Epoch 143/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8867 - loss: 0.3648 - val_accuracy: 0.6380 - val_loss: 0.9429\n",
      "Epoch 144/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8514 - loss: 0.4063 - val_accuracy: 0.6109 - val_loss: 1.0024\n",
      "Epoch 145/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8695 - loss: 0.3764 - val_accuracy: 0.6471 - val_loss: 0.9384\n",
      "Epoch 146/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8739 - loss: 0.3478 - val_accuracy: 0.6425 - val_loss: 0.9776\n",
      "Epoch 147/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8634 - loss: 0.3896 - val_accuracy: 0.6471 - val_loss: 0.9655\n",
      "Epoch 148/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8723 - loss: 0.3676 - val_accuracy: 0.6833 - val_loss: 0.9541\n",
      "Epoch 149/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8700 - loss: 0.3660 - val_accuracy: 0.6697 - val_loss: 0.9510\n",
      "Epoch 150/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8762 - loss: 0.3586 - val_accuracy: 0.6606 - val_loss: 0.9579\n",
      "Epoch 151/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8681 - loss: 0.3565 - val_accuracy: 0.6199 - val_loss: 0.9953\n",
      "Epoch 152/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8871 - loss: 0.3586 - val_accuracy: 0.6787 - val_loss: 0.9633\n",
      "Epoch 153/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8738 - loss: 0.3439 - val_accuracy: 0.6335 - val_loss: 1.0149\n",
      "Epoch 154/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8587 - loss: 0.3834 - val_accuracy: 0.6561 - val_loss: 0.9779\n",
      "Epoch 155/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8796 - loss: 0.3484 - val_accuracy: 0.6652 - val_loss: 0.9965\n",
      "Epoch 156/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8912 - loss: 0.3334 - val_accuracy: 0.6380 - val_loss: 0.9878\n",
      "Epoch 157/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8783 - loss: 0.3459 - val_accuracy: 0.5928 - val_loss: 1.1719\n",
      "Epoch 158/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8704 - loss: 0.3879 - val_accuracy: 0.6606 - val_loss: 0.9922\n",
      "Epoch 159/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8675 - loss: 0.3679 - val_accuracy: 0.6154 - val_loss: 1.0354\n",
      "Epoch 160/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8668 - loss: 0.3591 - val_accuracy: 0.6244 - val_loss: 1.0983\n",
      "Epoch 161/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8909 - loss: 0.3286 - val_accuracy: 0.6380 - val_loss: 1.0341\n",
      "Epoch 162/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8868 - loss: 0.3449 - val_accuracy: 0.6199 - val_loss: 1.0394\n",
      "Epoch 163/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8723 - loss: 0.3644 - val_accuracy: 0.6833 - val_loss: 1.0138\n",
      "Epoch 164/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8866 - loss: 0.3348 - val_accuracy: 0.6425 - val_loss: 1.0320\n",
      "Epoch 165/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8826 - loss: 0.3254 - val_accuracy: 0.6742 - val_loss: 1.0223\n",
      "Epoch 166/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9043 - loss: 0.3076 - val_accuracy: 0.6606 - val_loss: 1.0064\n",
      "Epoch 167/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8948 - loss: 0.3068 - val_accuracy: 0.6697 - val_loss: 1.0084\n",
      "Epoch 168/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9100 - loss: 0.2897 - val_accuracy: 0.6380 - val_loss: 1.0552\n",
      "Epoch 169/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8910 - loss: 0.3159 - val_accuracy: 0.6787 - val_loss: 1.0350\n",
      "Epoch 170/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8774 - loss: 0.3228 - val_accuracy: 0.6652 - val_loss: 1.0260\n",
      "Epoch 171/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9020 - loss: 0.3056 - val_accuracy: 0.6516 - val_loss: 1.1258\n",
      "Epoch 172/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8885 - loss: 0.3156 - val_accuracy: 0.6606 - val_loss: 1.0447\n",
      "Epoch 173/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9086 - loss: 0.2938 - val_accuracy: 0.6516 - val_loss: 1.0536\n",
      "Epoch 174/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9094 - loss: 0.2912 - val_accuracy: 0.6652 - val_loss: 1.0350\n",
      "Epoch 175/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9098 - loss: 0.2809 - val_accuracy: 0.6471 - val_loss: 1.1895\n",
      "Epoch 176/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9065 - loss: 0.2860 - val_accuracy: 0.6787 - val_loss: 1.0407\n",
      "Epoch 177/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9053 - loss: 0.2862 - val_accuracy: 0.6425 - val_loss: 1.0987\n",
      "Epoch 178/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9101 - loss: 0.2866 - val_accuracy: 0.6425 - val_loss: 1.0719\n",
      "Epoch 179/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9013 - loss: 0.2920 - val_accuracy: 0.6380 - val_loss: 1.0792\n",
      "Epoch 180/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8941 - loss: 0.2989 - val_accuracy: 0.6561 - val_loss: 1.0607\n",
      "Epoch 181/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8986 - loss: 0.2916 - val_accuracy: 0.6697 - val_loss: 1.0944\n",
      "Epoch 182/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9072 - loss: 0.2831 - val_accuracy: 0.6516 - val_loss: 1.0901\n",
      "Epoch 183/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9152 - loss: 0.2917 - val_accuracy: 0.6561 - val_loss: 1.1099\n",
      "Epoch 184/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9241 - loss: 0.2595 - val_accuracy: 0.6652 - val_loss: 1.1053\n",
      "Epoch 185/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9183 - loss: 0.2595 - val_accuracy: 0.6425 - val_loss: 1.1109\n",
      "Epoch 186/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9224 - loss: 0.2643 - val_accuracy: 0.6425 - val_loss: 1.1044\n",
      "Epoch 187/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9248 - loss: 0.2523 - val_accuracy: 0.6063 - val_loss: 1.1959\n",
      "Epoch 188/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8877 - loss: 0.2942 - val_accuracy: 0.6063 - val_loss: 1.2052\n",
      "Epoch 189/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9034 - loss: 0.2653 - val_accuracy: 0.6244 - val_loss: 1.1343\n",
      "Epoch 190/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8956 - loss: 0.2872 - val_accuracy: 0.6380 - val_loss: 1.2086\n",
      "Epoch 191/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9056 - loss: 0.2837 - val_accuracy: 0.6063 - val_loss: 1.1853\n",
      "Epoch 192/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9188 - loss: 0.2564 - val_accuracy: 0.6697 - val_loss: 1.1179\n",
      "Epoch 193/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9321 - loss: 0.2367 - val_accuracy: 0.6516 - val_loss: 1.1371\n",
      "Epoch 194/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9070 - loss: 0.2957 - val_accuracy: 0.6697 - val_loss: 1.1342\n",
      "Epoch 195/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9224 - loss: 0.2492 - val_accuracy: 0.6109 - val_loss: 1.1801\n",
      "Epoch 196/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9078 - loss: 0.2729 - val_accuracy: 0.6380 - val_loss: 1.1485\n",
      "Epoch 197/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9304 - loss: 0.2320 - val_accuracy: 0.6380 - val_loss: 1.1496\n",
      "Epoch 198/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9399 - loss: 0.2220 - val_accuracy: 0.6154 - val_loss: 1.1793\n",
      "Epoch 199/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9133 - loss: 0.2663 - val_accuracy: 0.6471 - val_loss: 1.1642\n",
      "Epoch 200/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9125 - loss: 0.2497 - val_accuracy: 0.6425 - val_loss: 1.1638\n",
      "Epoch 201/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9280 - loss: 0.2339 - val_accuracy: 0.6335 - val_loss: 1.1871\n",
      "Epoch 202/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9384 - loss: 0.2167 - val_accuracy: 0.6652 - val_loss: 1.2151\n",
      "Epoch 203/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9112 - loss: 0.2781 - val_accuracy: 0.5973 - val_loss: 1.4132\n",
      "Epoch 204/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8771 - loss: 0.3384 - val_accuracy: 0.6561 - val_loss: 1.1831\n",
      "Epoch 205/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9254 - loss: 0.2244 - val_accuracy: 0.6471 - val_loss: 1.1716\n",
      "Epoch 206/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9436 - loss: 0.2052 - val_accuracy: 0.6561 - val_loss: 1.2151\n",
      "Epoch 207/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9295 - loss: 0.2218 - val_accuracy: 0.6561 - val_loss: 1.2073\n",
      "Epoch 208/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9445 - loss: 0.2030 - val_accuracy: 0.6606 - val_loss: 1.2222\n",
      "Epoch 209/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9293 - loss: 0.2093 - val_accuracy: 0.5928 - val_loss: 1.2732\n",
      "Epoch 210/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9253 - loss: 0.2275 - val_accuracy: 0.6606 - val_loss: 1.2124\n",
      "Epoch 211/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9314 - loss: 0.2259 - val_accuracy: 0.6335 - val_loss: 1.2303\n",
      "Epoch 212/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9518 - loss: 0.1871 - val_accuracy: 0.6335 - val_loss: 1.2577\n",
      "Epoch 213/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9504 - loss: 0.1898 - val_accuracy: 0.6561 - val_loss: 1.2103\n",
      "Epoch 214/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9501 - loss: 0.1909 - val_accuracy: 0.6199 - val_loss: 1.2304\n",
      "Epoch 215/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9474 - loss: 0.2027 - val_accuracy: 0.6335 - val_loss: 1.2409\n",
      "Epoch 216/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9530 - loss: 0.1741 - val_accuracy: 0.6063 - val_loss: 1.3110\n",
      "Epoch 217/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9432 - loss: 0.2052 - val_accuracy: 0.6199 - val_loss: 1.2542\n",
      "Epoch 218/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9578 - loss: 0.1830 - val_accuracy: 0.6244 - val_loss: 1.2672\n",
      "Epoch 219/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9574 - loss: 0.1805 - val_accuracy: 0.6425 - val_loss: 1.3081\n",
      "Epoch 220/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9497 - loss: 0.1792 - val_accuracy: 0.6063 - val_loss: 1.3120\n",
      "Epoch 221/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9513 - loss: 0.1761 - val_accuracy: 0.6561 - val_loss: 1.2677\n",
      "Epoch 222/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9400 - loss: 0.1787 - val_accuracy: 0.6380 - val_loss: 1.3193\n",
      "Epoch 223/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9504 - loss: 0.1890 - val_accuracy: 0.6244 - val_loss: 1.3094\n",
      "Epoch 224/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9418 - loss: 0.1835 - val_accuracy: 0.6244 - val_loss: 1.3078\n",
      "Epoch 225/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9456 - loss: 0.1813 - val_accuracy: 0.6606 - val_loss: 1.3223\n",
      "Epoch 226/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9577 - loss: 0.1764 - val_accuracy: 0.6742 - val_loss: 1.3330\n",
      "Epoch 227/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9551 - loss: 0.1688 - val_accuracy: 0.6561 - val_loss: 1.3393\n",
      "Epoch 228/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9439 - loss: 0.1968 - val_accuracy: 0.6471 - val_loss: 1.3338\n",
      "Epoch 229/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9528 - loss: 0.1641 - val_accuracy: 0.6244 - val_loss: 1.3515\n",
      "Epoch 230/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9652 - loss: 0.1609 - val_accuracy: 0.5701 - val_loss: 1.4441\n",
      "Epoch 231/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9136 - loss: 0.2293 - val_accuracy: 0.6380 - val_loss: 1.3306\n",
      "Epoch 232/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9532 - loss: 0.1659 - val_accuracy: 0.6425 - val_loss: 1.3554\n",
      "Epoch 233/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9526 - loss: 0.1652 - val_accuracy: 0.6425 - val_loss: 1.3780\n",
      "Epoch 234/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9406 - loss: 0.1926 - val_accuracy: 0.6335 - val_loss: 1.3463\n",
      "Epoch 235/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9552 - loss: 0.1698 - val_accuracy: 0.6652 - val_loss: 1.4107\n",
      "Epoch 236/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9452 - loss: 0.1811 - val_accuracy: 0.6471 - val_loss: 1.3932\n",
      "Epoch 237/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9516 - loss: 0.1566 - val_accuracy: 0.6199 - val_loss: 1.4332\n",
      "Epoch 238/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9374 - loss: 0.1845 - val_accuracy: 0.6154 - val_loss: 1.3983\n",
      "Epoch 239/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9408 - loss: 0.1806 - val_accuracy: 0.6380 - val_loss: 1.3765\n",
      "Epoch 240/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9694 - loss: 0.1376 - val_accuracy: 0.5973 - val_loss: 1.5143\n",
      "Epoch 241/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9049 - loss: 0.2624 - val_accuracy: 0.6063 - val_loss: 1.4580\n",
      "Epoch 242/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9174 - loss: 0.2225 - val_accuracy: 0.6290 - val_loss: 1.4300\n",
      "Epoch 243/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9543 - loss: 0.1626 - val_accuracy: 0.6742 - val_loss: 1.5043\n",
      "Epoch 244/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9438 - loss: 0.1845 - val_accuracy: 0.6380 - val_loss: 1.4106\n",
      "Epoch 245/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9664 - loss: 0.1417 - val_accuracy: 0.6199 - val_loss: 1.4323\n",
      "Epoch 246/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9641 - loss: 0.1444 - val_accuracy: 0.6606 - val_loss: 1.4238\n",
      "Epoch 247/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9719 - loss: 0.1286 - val_accuracy: 0.6335 - val_loss: 1.4118\n",
      "Epoch 248/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9646 - loss: 0.1329 - val_accuracy: 0.6199 - val_loss: 1.4466\n",
      "Epoch 249/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9698 - loss: 0.1354 - val_accuracy: 0.6335 - val_loss: 1.4733\n",
      "Epoch 250/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9504 - loss: 0.1507 - val_accuracy: 0.6380 - val_loss: 1.4381\n",
      "Epoch 251/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9696 - loss: 0.1244 - val_accuracy: 0.6425 - val_loss: 1.4830\n",
      "Epoch 252/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9509 - loss: 0.1578 - val_accuracy: 0.6425 - val_loss: 1.4560\n",
      "Epoch 253/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9696 - loss: 0.1226 - val_accuracy: 0.6471 - val_loss: 1.4802\n",
      "Epoch 254/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9722 - loss: 0.1233 - val_accuracy: 0.6425 - val_loss: 1.4640\n",
      "Epoch 255/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9781 - loss: 0.1180 - val_accuracy: 0.6154 - val_loss: 1.4999\n",
      "Epoch 256/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9740 - loss: 0.1131 - val_accuracy: 0.5928 - val_loss: 1.5648\n",
      "Epoch 257/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9717 - loss: 0.1215 - val_accuracy: 0.6335 - val_loss: 1.4871\n",
      "Epoch 258/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9764 - loss: 0.1182 - val_accuracy: 0.6018 - val_loss: 1.5453\n",
      "Epoch 259/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9684 - loss: 0.1205 - val_accuracy: 0.6425 - val_loss: 1.5118\n",
      "Epoch 260/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9739 - loss: 0.1112 - val_accuracy: 0.6561 - val_loss: 1.5777\n",
      "Epoch 261/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9732 - loss: 0.1270 - val_accuracy: 0.6244 - val_loss: 1.5326\n",
      "Epoch 262/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9711 - loss: 0.1182 - val_accuracy: 0.6335 - val_loss: 1.5320\n",
      "Epoch 263/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9670 - loss: 0.1283 - val_accuracy: 0.6561 - val_loss: 1.5777\n",
      "Epoch 264/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9769 - loss: 0.0988 - val_accuracy: 0.6109 - val_loss: 1.8080\n",
      "Epoch 265/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8824 - loss: 0.3286 - val_accuracy: 0.6561 - val_loss: 1.5678\n",
      "Epoch 266/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9759 - loss: 0.1139 - val_accuracy: 0.6425 - val_loss: 1.5473\n",
      "Epoch 267/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9839 - loss: 0.0974 - val_accuracy: 0.6380 - val_loss: 1.5991\n",
      "Epoch 268/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9783 - loss: 0.1069 - val_accuracy: 0.6244 - val_loss: 1.6099\n",
      "Epoch 269/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9794 - loss: 0.1019 - val_accuracy: 0.6425 - val_loss: 1.6224\n",
      "Epoch 270/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9620 - loss: 0.1415 - val_accuracy: 0.6380 - val_loss: 1.5957\n",
      "Epoch 271/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9780 - loss: 0.1042 - val_accuracy: 0.6425 - val_loss: 1.6107\n",
      "Epoch 272/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9808 - loss: 0.0983 - val_accuracy: 0.6516 - val_loss: 1.7140\n",
      "Epoch 273/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9374 - loss: 0.1737 - val_accuracy: 0.6697 - val_loss: 1.6567\n",
      "Epoch 274/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9734 - loss: 0.0974 - val_accuracy: 0.6380 - val_loss: 1.6145\n",
      "Epoch 275/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9836 - loss: 0.0886 - val_accuracy: 0.6787 - val_loss: 1.6448\n",
      "Epoch 276/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9761 - loss: 0.1049 - val_accuracy: 0.6561 - val_loss: 1.6538\n",
      "Epoch 277/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9786 - loss: 0.0895 - val_accuracy: 0.6335 - val_loss: 1.6645\n",
      "Epoch 278/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9744 - loss: 0.0992 - val_accuracy: 0.6561 - val_loss: 1.7039\n",
      "Epoch 279/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9578 - loss: 0.1386 - val_accuracy: 0.6471 - val_loss: 1.6455\n",
      "Epoch 280/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9850 - loss: 0.0823 - val_accuracy: 0.6516 - val_loss: 1.6941\n",
      "Epoch 281/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9748 - loss: 0.0946 - val_accuracy: 0.6561 - val_loss: 1.6671\n",
      "Epoch 282/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9872 - loss: 0.0845 - val_accuracy: 0.6516 - val_loss: 1.6986\n",
      "Epoch 283/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9749 - loss: 0.0968 - val_accuracy: 0.6335 - val_loss: 1.6889\n",
      "Epoch 284/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9611 - loss: 0.1267 - val_accuracy: 0.6425 - val_loss: 1.6717\n",
      "Epoch 285/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9769 - loss: 0.0979 - val_accuracy: 0.6335 - val_loss: 1.7363\n",
      "Epoch 286/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9827 - loss: 0.0876 - val_accuracy: 0.6471 - val_loss: 1.7168\n",
      "Epoch 287/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9861 - loss: 0.0731 - val_accuracy: 0.6516 - val_loss: 1.7204\n",
      "Epoch 288/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9800 - loss: 0.0838 - val_accuracy: 0.6561 - val_loss: 1.7220\n",
      "Epoch 289/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9917 - loss: 0.0725 - val_accuracy: 0.6380 - val_loss: 1.7608\n",
      "Epoch 290/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9884 - loss: 0.0743 - val_accuracy: 0.6561 - val_loss: 1.7380\n",
      "Epoch 291/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9835 - loss: 0.0817 - val_accuracy: 0.6380 - val_loss: 1.7691\n",
      "Epoch 292/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9879 - loss: 0.0706 - val_accuracy: 0.6380 - val_loss: 1.7933\n",
      "Epoch 293/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9841 - loss: 0.0797 - val_accuracy: 0.6380 - val_loss: 1.8482\n",
      "Epoch 294/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9738 - loss: 0.0988 - val_accuracy: 0.6471 - val_loss: 1.7554\n",
      "Epoch 295/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9372 - loss: 0.1819 - val_accuracy: 0.6561 - val_loss: 1.7724\n",
      "Epoch 296/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9898 - loss: 0.0728 - val_accuracy: 0.6018 - val_loss: 1.8640\n",
      "Epoch 297/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9873 - loss: 0.0710 - val_accuracy: 0.6787 - val_loss: 1.7912\n",
      "Epoch 298/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9880 - loss: 0.0693 - val_accuracy: 0.6561 - val_loss: 1.7950\n",
      "Epoch 299/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9785 - loss: 0.0802 - val_accuracy: 0.6652 - val_loss: 1.7836\n",
      "Epoch 300/300\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9879 - loss: 0.0673 - val_accuracy: 0.6561 - val_loss: 1.8496\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=100)\n",
    "history = cnn.fit(X,y,batch_size=30,epochs=300,validation_split=0.1,shuffle=True,callbacks=[es])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01670336, 0.01062497, 0.01490494, 0.01078865, 0.02830837],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_layer_weights = cnn.layers[0].get_weights()\n",
    "\n",
    "# first_layer_weights is a list where the first element is the weights and the second is the biases\n",
    "weights, biases = first_layer_weights\n",
    "biases[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating synthetic galaxy images using GANs on which we will perform classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Define the directory containing .npy files\n",
    "directory_e = 'train/E'\n",
    "directory_s = 'train/S'\n",
    "directory_sb = 'train/SB'\n",
    "\n",
    "# Get a list of all .npy files in the directory\n",
    "files_e = [f for f in os.listdir(directory_e) if f.endswith('.jpg')]\n",
    "files_s = [f for f in os.listdir(directory_s) if f.endswith('.jpg')]\n",
    "files_sb = [f for f in os.listdir(directory_sb) if f.endswith('.jpg')]\n",
    "\n",
    "data_e_gan = []\n",
    "data_s_gan = []\n",
    "data_sb_gan = []\n",
    "\n",
    "for file in files_e:\n",
    "    file_path = os.path.join(directory_e, file)\n",
    "    image = Image.open(file_path)\n",
    "    image = image.resize((28,28))\n",
    "    data_e_gan.append(image)\n",
    "for file in files_s:\n",
    "    file_path = os.path.join(directory_s, file)\n",
    "    image = Image.open(file_path)\n",
    "    image = image.resize((28,28))\n",
    "    data_s_gan.append(image)\n",
    "for file in files_sb:\n",
    "    file_path = os.path.join(directory_sb, file)\n",
    "    image = Image.open(file_path)\n",
    "    image = image.resize((28,28))\n",
    "    data_sb_gan.append(image)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\surya\\AppData\\Local\\Temp\\ipykernel_18708\\3194570370.py:1: FutureWarning: The input object of type 'Image' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Image', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  data_e_gan = np.array(data_e_gan)\n",
      "C:\\Users\\surya\\AppData\\Local\\Temp\\ipykernel_18708\\3194570370.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  data_e_gan = np.array(data_e_gan)\n",
      "C:\\Users\\surya\\AppData\\Local\\Temp\\ipykernel_18708\\3194570370.py:2: FutureWarning: The input object of type 'Image' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Image', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  data_s_gan = np.array(data_s_gan)\n",
      "C:\\Users\\surya\\AppData\\Local\\Temp\\ipykernel_18708\\3194570370.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  data_s_gan = np.array(data_s_gan)\n",
      "C:\\Users\\surya\\AppData\\Local\\Temp\\ipykernel_18708\\3194570370.py:3: FutureWarning: The input object of type 'Image' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Image', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  data_sb_gan = np.array(data_sb_gan)\n",
      "C:\\Users\\surya\\AppData\\Local\\Temp\\ipykernel_18708\\3194570370.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  data_sb_gan = np.array(data_sb_gan)\n"
     ]
    }
   ],
   "source": [
    "data_e_gan = np.array(data_e_gan)\n",
    "data_s_gan = np.array(data_s_gan)\n",
    "data_sb_gan = np.array(data_sb_gan)\n",
    "for e in range(len(data_e_gan)):\n",
    "    data_e_gan[e] = np.array(data_e_gan[e])\n",
    "    # print(e.shape)\n",
    "for s in range(len(data_s_gan)):\n",
    "    data_s_gan[s] = np.array(data_s_gan[s])\n",
    "for sb in range(len(data_sb_gan)):\n",
    "    data_sb_gan[sb] = np.array(data_sb_gan[sb])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_grayscale(image_array):\n",
    "    \"\"\"\n",
    "    Convert an RGB image to grayscale using the luminosity method.\n",
    "    The weights are based on the human perception of colors.\n",
    "    \"\"\"\n",
    "    r, g, b = image_array[:,:,0], image_array[:,:,1], image_array[:,:,2]\n",
    "    grayscale_image = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "    return grayscale_image\n",
    "\n",
    "\n",
    "for e in range(len(data_e_gan)):\n",
    "    data_e_gan[e] = rgb_to_grayscale(data_e_gan[e])\n",
    "    # print(e.shape)\n",
    "for s in range(len(data_s_gan)):\n",
    "    data_s_gan[s] = rgb_to_grayscale(data_s_gan[s])\n",
    "for sb in range(len(data_sb_gan)):\n",
    "    data_sb_gan[sb] = rgb_to_grayscale(data_sb_gan[sb])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2203, 28, 28, 1)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_gan = np.concatenate((list(data_e_gan),list(data_s_gan),list(data_sb_gan)),axis=0)\n",
    "data_gan = data_gan.reshape(-1,28,28,1)\n",
    "data_gan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(data_gan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2203, 28, 28, 1)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_gan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1fa40edc590>"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data_gan[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_gan[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 2203\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "# train_dataset = tf.data.Dataset.from_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*64,input_shape=(200,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((7, 7, 64)))\n",
    "    assert model.output_shape == (None, 7, 7, 64)  # Note: None is the batch size\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1fa137687d0>"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.colors import LogNorm\n",
    "generator = generator_model()\n",
    "\n",
    "noise = tf.random.normal([1, 200])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='viridis', norm=LogNorm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_11\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3136</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">630,336</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3136</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,544</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3136</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_9              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">204,800</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_10             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │       <span style=\"color: #00af00; text-decoration-color: #00af00\">204,800</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_11             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,600</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3136\u001b[0m)           │       \u001b[38;5;34m630,336\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3136\u001b[0m)           │        \u001b[38;5;34m12,544\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_11 (\u001b[38;5;33mLeakyReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3136\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_3 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_9              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m204,800\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_12 (\u001b[38;5;33mLeakyReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_10             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │       \u001b[38;5;34m204,800\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_13 (\u001b[38;5;33mLeakyReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_11             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │         \u001b[38;5;34m1,600\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,054,848</span> (4.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,054,848\u001b[0m (4.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,048,192</span> (4.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,048,192\u001b[0m (4.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,656</span> (26.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m6,656\u001b[0m (26.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (4, 4), strides=(2, 2), padding='same',\n",
    "                                     input_shape=(28, 28, 1)))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (4, 4), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.00468476]], shape=(1, 1), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\surya\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "decision = discriminator(generated_image)\n",
    "print (decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method returns a helper function to compute cross entropy loss\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_out, fake_out):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_out),real_out)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_out),fake_out)\n",
    "    return real_loss + fake_loss\n",
    "\n",
    "def generator_loss(fake_out):\n",
    "    return cross_entropy(tf.ones_like(fake_out),fake_out)\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "noise_dim = 200\n",
    "num_examples_to_generate = 20\n",
    "\n",
    "# You will reuse this seed overtime (so it's easier)\n",
    "# to visualize progress in the animated GIF)\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        gen_imgs = generator(noise, training=True)\n",
    "\n",
    "        real_out = discriminator(images,training= True)\n",
    "        fake_out = discriminator(gen_imgs, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_out)\n",
    "        disc_loss = discriminator_loss(real_out,fake_out)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib.colors import LogNorm\n",
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  # Notice `training` is set to False.\n",
    "  # This is so all layers run in inference mode (batchnorm).\n",
    "  predictions = model(test_input, training=False)\n",
    "\n",
    "  fig = plt.figure(figsize=(8,8))\n",
    "\n",
    "  for i in range(predictions.shape[0]):\n",
    "      # plt.subplot(4, 4, i+1)\n",
    "      plt.imshow(predictions[i, :, :, 0] * 255, cmap='viridis',norm=LogNorm())\n",
    "      plt.axis('off')\n",
    "\n",
    "  plt.savefig('generated_images/image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def train(dataset, epochs):\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "\n",
    "    for image_batch in dataset:\n",
    "      train_step(image_batch)\n",
    "\n",
    "    # Produce images for the GIF as you go\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator,\n",
    "                             epoch + 1,\n",
    "                             seed)\n",
    "\n",
    "    # Save the model every 15 epochs\n",
    "    if (epoch + 1) % 15 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "  # Generate after the final epoch\n",
    "  display.clear_output(wait=True)\n",
    "  generate_and_save_images(generator,\n",
    "                           epochs,\n",
    "                           seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch and shuffle the data\n",
    "data_gan = data_gan /255\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(data_gan).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(train_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction on generated synthetic images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "directory = 'generated_images'\n",
    "\n",
    "images = [f for f in os.listdir(directory) if f.endswith('.png')]\n",
    "# print(imgs[0])\n",
    "imgs =[]\n",
    "\n",
    "for file in images:\n",
    "    file_path = os.path.join(directory, file)\n",
    "    image = Image.open(file_path)\n",
    "    # image = image.resize((28,28))\n",
    "    imgs.append(image)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\surya\\AppData\\Local\\Temp\\ipykernel_18708\\3139486963.py:1: FutureWarning: The input object of type 'PngImageFile' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'PngImageFile', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  imgs = np.array(imgs)\n",
      "C:\\Users\\surya\\AppData\\Local\\Temp\\ipykernel_18708\\3139486963.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  imgs = np.array(imgs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs = np.array(imgs)\n",
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(imgs)):\n",
    "    imgs[i] = np.array(imgs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 800, 4)"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgba_to_grayscale(image_array):\n",
    "    \"\"\"\n",
    "    Convert an RGB image to grayscale using the luminosity method.\n",
    "    The weights are based on the human perception of colors.\n",
    "    \"\"\"\n",
    "    r, g, b,a = image_array[:,:,0], image_array[:,:,1], image_array[:,:,2],image_array[:,:,3]\n",
    "    grayscale_image = 0.2989 * r + 0.5870 * g + 0.1140 * b + 0.0* a\n",
    "    return grayscale_image\n",
    "\n",
    "for i in range(len(imgs)):\n",
    "    imgs[i] = rgba_to_grayscale(imgs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 800)"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(imgs)):\n",
    "#     imgs[i]= np.mean(imgs[i],axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 800)"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gray_image=[]\n",
    "for i in range(100):\n",
    "    imgs[i].resize(28,28)\n",
    "\n",
    "    # imgs[i] = imgs[i].reshape((28,28))\n",
    "# imgs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = imgs/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999],\n",
       "       [0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999],\n",
       "       [0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999],\n",
       "       [0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999],\n",
       "       [0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999],\n",
       "       [0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999],\n",
       "       [0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999],\n",
       "       [0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999],\n",
       "       [0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999],\n",
       "       [0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999],\n",
       "       [0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999],\n",
       "       [0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999],\n",
       "       [0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999],\n",
       "       [0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999],\n",
       "       [0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999],\n",
       "       [0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999],\n",
       "       [0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999],\n",
       "       [0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999],\n",
       "       [0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999],\n",
       "       [0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999],\n",
       "       [0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999],\n",
       "       [0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999],\n",
       "       [0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999],\n",
       "       [0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999],\n",
       "       [0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999],\n",
       "       [0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999],\n",
       "       [0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999],\n",
       "       [0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
       "        0.9999, 0.9999, 0.9999, 0.9999]])"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs[0] = np.squeeze(imgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.0394137e-05, 9.9998963e-01, 2.3267482e-16]], dtype=float32)"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imgs[0] = np.expand_dims(imgs[0], axis=0)  # Add batch dimension\n",
    "# imgs[0] = np.expand_dims(imgs[0], axis=-1)  # Add channel dimension\n",
    "# cnn.predict(imgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn.predict(imgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred =[]\n",
    "y_list=[]\n",
    "gal=['Elliptical galaxy','Spiral galaxy', 'Barred-Spiral galaxy']\n",
    "pred_gal=[]\n",
    "for i in range(len(imgs)):\n",
    "    inverted_image_array =imgs[i]\n",
    "    inverted_image_array = np.expand_dims(inverted_image_array, axis=0)  # Add batch dimension\n",
    "    inverted_image_array = np.expand_dims(inverted_image_array, axis=-1)  # Add channel dimension\n",
    "    y_list.append(np.max(cnn.predict(inverted_image_array)))\n",
    "    y_pred.append(np.argmax(cnn.predict(inverted_image_array)))\n",
    "    pred_gal.append(gal[np.argmax(cnn.predict(inverted_image_array))])\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896,\n",
       " 0.9999896]"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pred_gal=='Spiral galaxy'\n",
    "y_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "pred_gal = np.array(pred_gal)\n",
    "e_g = np.sum(pred_gal=='Elliptical galaxy')/100\n",
    "s_g = np.sum(pred_gal=='Spiral galaxy')/100\n",
    "sb_g = np.sum(pred_gal=='Barred-Spiral galaxy')/100\n",
    "\n",
    "print(e_g,s_g,sb_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs[0] = np.squeeze(imgs[0])\n",
    "\n",
    "# plt.imshow(imgs[0],cmap='viridis',norm=LogNorm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = Image.open('generated_images/image_at_epoch_0100.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=800x800>"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 800, 4)"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image1 = np.array(image1)\n",
    "image1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = rgba_to_grayscale(image1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745],\n",
       "       [254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745],\n",
       "       [254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745],\n",
       "       [254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745],\n",
       "       [254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745],\n",
       "       [254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745],\n",
       "       [254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745],\n",
       "       [254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745],\n",
       "       [254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745],\n",
       "       [254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745],\n",
       "       [254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745],\n",
       "       [254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745],\n",
       "       [254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745],\n",
       "       [254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745],\n",
       "       [254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745],\n",
       "       [254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745],\n",
       "       [254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745],\n",
       "       [254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745],\n",
       "       [254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745],\n",
       "       [254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745],\n",
       "       [254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745],\n",
       "       [254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745],\n",
       "       [254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745],\n",
       "       [254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745],\n",
       "       [254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745],\n",
       "       [254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745],\n",
       "       [254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745],\n",
       "       [254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745, 254.9745, 254.9745,\n",
       "        254.9745, 254.9745, 254.9745, 254.9745]])"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image1 = np.resize(image1,(28,28))\n",
    "image1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = image1/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.0394137e-05, 9.9998963e-01, 2.3267482e-16]], dtype=float32)"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image1 = np.expand_dims(image1, axis=0)  # Add batch dimension\n",
    "image1 = np.expand_dims(image1, axis=-1)  # Add channel dimension\n",
    "cnn.predict(image1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
